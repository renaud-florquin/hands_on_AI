{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Intro2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/renaud-florquin/hands_on_AI/blob/master/FireForest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2z18Vjr2bsu",
        "colab_type": "code",
        "outputId": "37fa4dc3-c219-404c-cc91-7dfb2989da1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Oct  5 13:47:42 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 430.40       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   72C    P8    34W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H318Syzc1-9c",
        "colab_type": "code",
        "outputId": "23fae62c-b1b7-4501-f26e-39f0460b2267",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYOqb0f49lDl",
        "colab_type": "text"
      },
      "source": [
        "Load the data and check the size of the train and test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCRebTMB2Vmq",
        "colab_type": "code",
        "outputId": "83248a99-a9d9-4582-b487-43f867d3c3be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data() "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWU-KvIP3BCM",
        "colab_type": "code",
        "outputId": "953eaeb8-2865-48e9-a0ff-69ca0438de58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print('x Train: ', x_train.shape)\n",
        "print('y Train: ', y_train.shape)\n",
        "print('x Test: ', x_test.shape)\n",
        "print('y Test: ', y_test.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x Train:  (60000, 28, 28)\n",
            "y Train:  (60000,)\n",
            "x Test:  (10000, 28, 28)\n",
            "y Test:  (10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcO26BFdFTN2",
        "colab_type": "text"
      },
      "source": [
        "Display the first images (X) and the corresponding labels (y)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jp_VaYid3I9w",
        "colab_type": "code",
        "outputId": "c80ccc5f-4424-4833-ff08-dff9d317cfcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        }
      },
      "source": [
        "amount = 20\n",
        "img_rows = 2\n",
        "img_columns = 4\n",
        "amount = img_rows * img_columns\n",
        "fig = plt.figure()\n",
        "\n",
        "for i in range(amount):\n",
        "    ax = fig.add_subplot(img_rows, img_columns, 1 + i)\n",
        "    plt.imshow(x_train[i], cmap='binary')\n",
        "    plt.title(y_train[i])\n",
        "    plt.xticks([]) \n",
        "    plt.yticks([])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAADhCAYAAAD/Ec//AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nA8j7uvo+Mcy7AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 8 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWNHqjS3NsWC",
        "colab_type": "text"
      },
      "source": [
        "Reshape the X tensor vector of images (N, h, w) to a vector of vectors (N, h*w)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEJLmh2c3Woh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1]*x_train.shape[2])\n",
        "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1]*x_test.shape[2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FN8tZhIiNwDb",
        "colab_type": "text"
      },
      "source": [
        "Normalize the pxel value to a range [0..1]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-rSGkBN3vtV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esnb5GqlN33c",
        "colab_type": "text"
      },
      "source": [
        "Transform the numerical value of a label to a categorical vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WrBb3kI37t1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nb_classes=10\n",
        "y_train = np_utils.to_categorical(y_train, nb_classes)\n",
        "y_test = np_utils.to_categorical(y_test, nb_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "5e16d54d-738d-4413-f7c2-3fd350417d3e",
        "id": "qgCY_5ddDP2j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 784)\n",
            "(60000, 10)\n",
            "(10000, 784)\n",
            "(10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6viHutb3nyo",
        "colab_type": "code",
        "outputId": "06a91bc5-95bf-499f-ea4c-bf8ed774a654",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train[0]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIQxFLNFSHqs",
        "colab_type": "text"
      },
      "source": [
        "## Using Sigmoid"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGB3DTxg28R2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_layer = tf.keras.layers.Input(shape=(784,))\n",
        "z = tf.keras.layers.Dense(200)(input_layer)\n",
        "z = tf.keras.layers.Activation('sigmoid')(z)\n",
        "z = tf.keras.layers.Dense(100)(z)\n",
        "z = tf.keras.layers.Activation('sigmoid')(z)\n",
        "z = tf.keras.layers.Dense(60)(z)\n",
        "z = tf.keras.layers.Activation('sigmoid')(z)\n",
        "z = tf.keras.layers.Dense(30)(z)\n",
        "z = tf.keras.layers.Activation('sigmoid')(z)\n",
        "z = tf.keras.layers.Dense(nb_classes)(z)\n",
        "output_layer = tf.keras.layers.Activation('softmax')(z)\n",
        "\n",
        "model_sigmoid = tf.keras.models.Model(input_layer, output_layer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5IRu_gy8Anx",
        "colab_type": "code",
        "outputId": "5fde8e55-6978-4ae6-9964-bc87ebee2bde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "model_sigmoid.summary()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         [(None, 784)]             0         \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 200)               157000    \n",
            "_________________________________________________________________\n",
            "activation_23 (Activation)   (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 100)               20100     \n",
            "_________________________________________________________________\n",
            "activation_24 (Activation)   (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 60)                6060      \n",
            "_________________________________________________________________\n",
            "activation_25 (Activation)   (None, 60)                0         \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 30)                1830      \n",
            "_________________________________________________________________\n",
            "activation_26 (Activation)   (None, 30)                0         \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 10)                310       \n",
            "_________________________________________________________________\n",
            "activation_27 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 185,300\n",
            "Trainable params: 185,300\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gee-rhC_23Ex",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_sigmoid.compile(loss='categorical_crossentropy', optimizer=\"SGD\", metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvwb9pIZ8pSJ",
        "colab_type": "code",
        "outputId": "a5055892-6ffb-4df8-eb6d-6849e00739bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model_sigmoid.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=100)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            "60000/60000 [==============================] - 7s 124us/sample - loss: 2.3022 - acc: 0.1108 - val_loss: 2.2998 - val_acc: 0.1135\n",
            "Epoch 2/100\n",
            "60000/60000 [==============================] - 7s 122us/sample - loss: 2.3000 - acc: 0.1148 - val_loss: 2.2989 - val_acc: 0.1147\n",
            "Epoch 3/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 2.2984 - acc: 0.1174 - val_loss: 2.2977 - val_acc: 0.1135\n",
            "Epoch 4/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 2.2969 - acc: 0.1232 - val_loss: 2.2954 - val_acc: 0.1135\n",
            "Epoch 5/100\n",
            "60000/60000 [==============================] - 7s 122us/sample - loss: 2.2947 - acc: 0.1292 - val_loss: 2.2927 - val_acc: 0.1910\n",
            "Epoch 6/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 2.2917 - acc: 0.1380 - val_loss: 2.2891 - val_acc: 0.1147\n",
            "Epoch 7/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 2.2873 - acc: 0.1491 - val_loss: 2.2832 - val_acc: 0.1380\n",
            "Epoch 8/100\n",
            "60000/60000 [==============================] - 8s 128us/sample - loss: 2.2796 - acc: 0.1692 - val_loss: 2.2739 - val_acc: 0.3058\n",
            "Epoch 9/100\n",
            "60000/60000 [==============================] - 7s 124us/sample - loss: 2.2641 - acc: 0.2285 - val_loss: 2.2497 - val_acc: 0.2991\n",
            "Epoch 10/100\n",
            "60000/60000 [==============================] - 7s 124us/sample - loss: 2.2232 - acc: 0.2853 - val_loss: 2.1798 - val_acc: 0.3311\n",
            "Epoch 11/100\n",
            "60000/60000 [==============================] - 7s 124us/sample - loss: 2.0837 - acc: 0.3351 - val_loss: 1.9463 - val_acc: 0.3573\n",
            "Epoch 12/100\n",
            "60000/60000 [==============================] - 7s 124us/sample - loss: 1.7731 - acc: 0.3878 - val_loss: 1.5949 - val_acc: 0.4076\n",
            "Epoch 13/100\n",
            "60000/60000 [==============================] - 7s 124us/sample - loss: 1.4833 - acc: 0.4437 - val_loss: 1.3968 - val_acc: 0.4717\n",
            "Epoch 14/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 1.3362 - acc: 0.4836 - val_loss: 1.2871 - val_acc: 0.4946\n",
            "Epoch 15/100\n",
            "60000/60000 [==============================] - 7s 125us/sample - loss: 1.2428 - acc: 0.5201 - val_loss: 1.2050 - val_acc: 0.5325\n",
            "Epoch 16/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 1.1657 - acc: 0.5610 - val_loss: 1.1307 - val_acc: 0.5767\n",
            "Epoch 17/100\n",
            "60000/60000 [==============================] - 7s 122us/sample - loss: 1.0937 - acc: 0.6053 - val_loss: 1.0586 - val_acc: 0.6257\n",
            "Epoch 18/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 1.0267 - acc: 0.6446 - val_loss: 0.9926 - val_acc: 0.6629\n",
            "Epoch 19/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 0.9655 - acc: 0.6752 - val_loss: 0.9337 - val_acc: 0.7005\n",
            "Epoch 20/100\n",
            "60000/60000 [==============================] - 7s 125us/sample - loss: 0.9098 - acc: 0.7037 - val_loss: 0.8785 - val_acc: 0.7206\n",
            "Epoch 21/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 0.8571 - acc: 0.7271 - val_loss: 0.8286 - val_acc: 0.7480\n",
            "Epoch 22/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 0.8044 - acc: 0.7504 - val_loss: 0.7729 - val_acc: 0.7655\n",
            "Epoch 23/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 0.7492 - acc: 0.7728 - val_loss: 0.7169 - val_acc: 0.7882\n",
            "Epoch 24/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 0.6897 - acc: 0.7975 - val_loss: 0.6588 - val_acc: 0.8111\n",
            "Epoch 25/100\n",
            "60000/60000 [==============================] - 7s 124us/sample - loss: 0.6279 - acc: 0.8186 - val_loss: 0.5941 - val_acc: 0.8292\n",
            "Epoch 26/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 0.5697 - acc: 0.8386 - val_loss: 0.5391 - val_acc: 0.8479\n",
            "Epoch 27/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 0.5235 - acc: 0.8525 - val_loss: 0.4985 - val_acc: 0.8580\n",
            "Epoch 28/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 0.4892 - acc: 0.8617 - val_loss: 0.4678 - val_acc: 0.8671\n",
            "Epoch 29/100\n",
            "60000/60000 [==============================] - 7s 125us/sample - loss: 0.4633 - acc: 0.8682 - val_loss: 0.4454 - val_acc: 0.8709\n",
            "Epoch 30/100\n",
            "60000/60000 [==============================] - 8s 130us/sample - loss: 0.4422 - acc: 0.8743 - val_loss: 0.4255 - val_acc: 0.8783\n",
            "Epoch 31/100\n",
            "60000/60000 [==============================] - 8s 133us/sample - loss: 0.4244 - acc: 0.8799 - val_loss: 0.4178 - val_acc: 0.8810\n",
            "Epoch 32/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 0.4090 - acc: 0.8845 - val_loss: 0.3954 - val_acc: 0.8859\n",
            "Epoch 33/100\n",
            "60000/60000 [==============================] - 7s 122us/sample - loss: 0.3951 - acc: 0.8887 - val_loss: 0.3839 - val_acc: 0.8896\n",
            "Epoch 34/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 0.3821 - acc: 0.8923 - val_loss: 0.3735 - val_acc: 0.8932\n",
            "Epoch 35/100\n",
            "60000/60000 [==============================] - 7s 121us/sample - loss: 0.3703 - acc: 0.8954 - val_loss: 0.3614 - val_acc: 0.8970\n",
            "Epoch 36/100\n",
            "60000/60000 [==============================] - 7s 122us/sample - loss: 0.3592 - acc: 0.8990 - val_loss: 0.3513 - val_acc: 0.9002\n",
            "Epoch 37/100\n",
            "60000/60000 [==============================] - 7s 122us/sample - loss: 0.3483 - acc: 0.9020 - val_loss: 0.3406 - val_acc: 0.9035\n",
            "Epoch 38/100\n",
            "60000/60000 [==============================] - 7s 121us/sample - loss: 0.3380 - acc: 0.9048 - val_loss: 0.3332 - val_acc: 0.9060\n",
            "Epoch 39/100\n",
            "60000/60000 [==============================] - 7s 122us/sample - loss: 0.3283 - acc: 0.9076 - val_loss: 0.3231 - val_acc: 0.9084\n",
            "Epoch 40/100\n",
            "60000/60000 [==============================] - 7s 122us/sample - loss: 0.3188 - acc: 0.9106 - val_loss: 0.3126 - val_acc: 0.9118\n",
            "Epoch 41/100\n",
            "60000/60000 [==============================] - 7s 122us/sample - loss: 0.3094 - acc: 0.9131 - val_loss: 0.3053 - val_acc: 0.9141\n",
            "Epoch 42/100\n",
            "60000/60000 [==============================] - 7s 125us/sample - loss: 0.3007 - acc: 0.9150 - val_loss: 0.2990 - val_acc: 0.9146\n",
            "Epoch 43/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 0.2926 - acc: 0.9173 - val_loss: 0.2918 - val_acc: 0.9177\n",
            "Epoch 44/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 0.2844 - acc: 0.9199 - val_loss: 0.2837 - val_acc: 0.9203\n",
            "Epoch 45/100\n",
            "60000/60000 [==============================] - 7s 122us/sample - loss: 0.2765 - acc: 0.9220 - val_loss: 0.2773 - val_acc: 0.9225\n",
            "Epoch 46/100\n",
            "60000/60000 [==============================] - 7s 122us/sample - loss: 0.2690 - acc: 0.9242 - val_loss: 0.2699 - val_acc: 0.9233\n",
            "Epoch 47/100\n",
            "60000/60000 [==============================] - 7s 121us/sample - loss: 0.2616 - acc: 0.9261 - val_loss: 0.2610 - val_acc: 0.9267\n",
            "Epoch 48/100\n",
            "60000/60000 [==============================] - 7s 122us/sample - loss: 0.2549 - acc: 0.9279 - val_loss: 0.2580 - val_acc: 0.9266\n",
            "Epoch 49/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 0.2481 - acc: 0.9301 - val_loss: 0.2497 - val_acc: 0.9286\n",
            "Epoch 50/100\n",
            "60000/60000 [==============================] - 7s 124us/sample - loss: 0.2420 - acc: 0.9319 - val_loss: 0.2447 - val_acc: 0.9304\n",
            "Epoch 51/100\n",
            "60000/60000 [==============================] - 7s 124us/sample - loss: 0.2357 - acc: 0.9330 - val_loss: 0.2375 - val_acc: 0.9324\n",
            "Epoch 52/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 0.2296 - acc: 0.9349 - val_loss: 0.2336 - val_acc: 0.9350\n",
            "Epoch 53/100\n",
            "60000/60000 [==============================] - 7s 124us/sample - loss: 0.2241 - acc: 0.9367 - val_loss: 0.2283 - val_acc: 0.9353\n",
            "Epoch 54/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 0.2185 - acc: 0.9388 - val_loss: 0.2216 - val_acc: 0.9373\n",
            "Epoch 55/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 0.2132 - acc: 0.9408 - val_loss: 0.2175 - val_acc: 0.9391\n",
            "Epoch 56/100\n",
            "60000/60000 [==============================] - 7s 124us/sample - loss: 0.2086 - acc: 0.9414 - val_loss: 0.2136 - val_acc: 0.9392\n",
            "Epoch 57/100\n",
            "60000/60000 [==============================] - 7s 124us/sample - loss: 0.2035 - acc: 0.9428 - val_loss: 0.2128 - val_acc: 0.9397\n",
            "Epoch 58/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 0.1987 - acc: 0.9446 - val_loss: 0.2059 - val_acc: 0.9419\n",
            "Epoch 59/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 0.1945 - acc: 0.9453 - val_loss: 0.2002 - val_acc: 0.9428\n",
            "Epoch 60/100\n",
            "60000/60000 [==============================] - 7s 122us/sample - loss: 0.1902 - acc: 0.9466 - val_loss: 0.1981 - val_acc: 0.9429\n",
            "Epoch 61/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 0.1861 - acc: 0.9480 - val_loss: 0.1945 - val_acc: 0.9450\n",
            "Epoch 62/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 0.1823 - acc: 0.9486 - val_loss: 0.1931 - val_acc: 0.9456\n",
            "Epoch 63/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 0.1784 - acc: 0.9495 - val_loss: 0.1894 - val_acc: 0.9460\n",
            "Epoch 64/100\n",
            "60000/60000 [==============================] - 7s 122us/sample - loss: 0.1745 - acc: 0.9502 - val_loss: 0.1952 - val_acc: 0.9443\n",
            "Epoch 65/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 0.1708 - acc: 0.9520 - val_loss: 0.1822 - val_acc: 0.9487\n",
            "Epoch 66/100\n",
            "60000/60000 [==============================] - 7s 122us/sample - loss: 0.1675 - acc: 0.9528 - val_loss: 0.1816 - val_acc: 0.9493\n",
            "Epoch 67/100\n",
            "60000/60000 [==============================] - 7s 124us/sample - loss: 0.1641 - acc: 0.9538 - val_loss: 0.1809 - val_acc: 0.9475\n",
            "Epoch 68/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 0.1607 - acc: 0.9545 - val_loss: 0.1726 - val_acc: 0.9497\n",
            "Epoch 69/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 0.1578 - acc: 0.9557 - val_loss: 0.1723 - val_acc: 0.9502\n",
            "Epoch 70/100\n",
            "60000/60000 [==============================] - 7s 124us/sample - loss: 0.1547 - acc: 0.9566 - val_loss: 0.1691 - val_acc: 0.9510\n",
            "Epoch 71/100\n",
            "60000/60000 [==============================] - 7s 124us/sample - loss: 0.1515 - acc: 0.9577 - val_loss: 0.1704 - val_acc: 0.9520\n",
            "Epoch 72/100\n",
            "60000/60000 [==============================] - 8s 135us/sample - loss: 0.1486 - acc: 0.9581 - val_loss: 0.1633 - val_acc: 0.9528\n",
            "Epoch 73/100\n",
            "60000/60000 [==============================] - 8s 131us/sample - loss: 0.1461 - acc: 0.9591 - val_loss: 0.1630 - val_acc: 0.9531\n",
            "Epoch 74/100\n",
            "60000/60000 [==============================] - 7s 124us/sample - loss: 0.1433 - acc: 0.9593 - val_loss: 0.1601 - val_acc: 0.9529\n",
            "Epoch 75/100\n",
            "60000/60000 [==============================] - 7s 124us/sample - loss: 0.1404 - acc: 0.9605 - val_loss: 0.1569 - val_acc: 0.9537\n",
            "Epoch 76/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 0.1378 - acc: 0.9611 - val_loss: 0.1583 - val_acc: 0.9540\n",
            "Epoch 77/100\n",
            "60000/60000 [==============================] - 7s 122us/sample - loss: 0.1354 - acc: 0.9621 - val_loss: 0.1546 - val_acc: 0.9552\n",
            "Epoch 78/100\n",
            "60000/60000 [==============================] - 7s 122us/sample - loss: 0.1328 - acc: 0.9625 - val_loss: 0.1520 - val_acc: 0.9567\n",
            "Epoch 79/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 0.1307 - acc: 0.9628 - val_loss: 0.1496 - val_acc: 0.9560\n",
            "Epoch 80/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 0.1281 - acc: 0.9640 - val_loss: 0.1479 - val_acc: 0.9571\n",
            "Epoch 81/100\n",
            "60000/60000 [==============================] - 7s 124us/sample - loss: 0.1263 - acc: 0.9646 - val_loss: 0.1462 - val_acc: 0.9570\n",
            "Epoch 82/100\n",
            "60000/60000 [==============================] - 7s 122us/sample - loss: 0.1237 - acc: 0.9650 - val_loss: 0.1494 - val_acc: 0.9551\n",
            "Epoch 83/100\n",
            "60000/60000 [==============================] - 7s 122us/sample - loss: 0.1218 - acc: 0.9651 - val_loss: 0.1426 - val_acc: 0.9576\n",
            "Epoch 84/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 0.1198 - acc: 0.9662 - val_loss: 0.1426 - val_acc: 0.9586\n",
            "Epoch 85/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 0.1174 - acc: 0.9668 - val_loss: 0.1424 - val_acc: 0.9595\n",
            "Epoch 86/100\n",
            "60000/60000 [==============================] - 7s 122us/sample - loss: 0.1156 - acc: 0.9673 - val_loss: 0.1401 - val_acc: 0.9586\n",
            "Epoch 87/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 0.1137 - acc: 0.9682 - val_loss: 0.1380 - val_acc: 0.9600\n",
            "Epoch 88/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 0.1116 - acc: 0.9686 - val_loss: 0.1403 - val_acc: 0.9595\n",
            "Epoch 89/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 0.1098 - acc: 0.9693 - val_loss: 0.1410 - val_acc: 0.9591\n",
            "Epoch 90/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 0.1081 - acc: 0.9703 - val_loss: 0.1335 - val_acc: 0.9613\n",
            "Epoch 91/100\n",
            "60000/60000 [==============================] - 7s 122us/sample - loss: 0.1066 - acc: 0.9701 - val_loss: 0.1320 - val_acc: 0.9611\n",
            "Epoch 92/100\n",
            "60000/60000 [==============================] - 7s 122us/sample - loss: 0.1043 - acc: 0.9710 - val_loss: 0.1374 - val_acc: 0.9586\n",
            "Epoch 93/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 0.1029 - acc: 0.9716 - val_loss: 0.1324 - val_acc: 0.9606\n",
            "Epoch 94/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 0.1012 - acc: 0.9719 - val_loss: 0.1294 - val_acc: 0.9620\n",
            "Epoch 95/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 0.0997 - acc: 0.9726 - val_loss: 0.1284 - val_acc: 0.9620\n",
            "Epoch 96/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 0.0980 - acc: 0.9730 - val_loss: 0.1267 - val_acc: 0.9625\n",
            "Epoch 97/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 0.0965 - acc: 0.9732 - val_loss: 0.1254 - val_acc: 0.9636\n",
            "Epoch 98/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 0.0948 - acc: 0.9738 - val_loss: 0.1241 - val_acc: 0.9641\n",
            "Epoch 99/100\n",
            "60000/60000 [==============================] - 7s 124us/sample - loss: 0.0935 - acc: 0.9740 - val_loss: 0.1262 - val_acc: 0.9634\n",
            "Epoch 100/100\n",
            "60000/60000 [==============================] - 7s 122us/sample - loss: 0.0921 - acc: 0.9745 - val_loss: 0.1327 - val_acc: 0.9621\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PR_DH9x0EYD3",
        "colab_type": "text"
      },
      "source": [
        "Plot the training and validation accuracy per epoch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRkuPRyf87RJ",
        "colab_type": "code",
        "outputId": "9e6af770-5091-4652-f2ee-ab8f3cb112a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        }
      },
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "epochs   = range(100) # Get number of epochs\n",
        "\n",
        "plt.plot(epochs, acc, 'b')\n",
        "plt.plot(epochs, val_acc, 'r')\n",
        "plt.title('Training accuracy')\n",
        "plt.figure()\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjkSbdmxSlZI",
        "colab_type": "text"
      },
      "source": [
        "## Model using ReLU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_DGh1CASop1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_layer = tf.keras.layers.Input(shape=(784,))\n",
        "z = tf.keras.layers.Dense(200)(input_layer)\n",
        "z = tf.keras.layers.Activation('relu')(z)\n",
        "z = tf.keras.layers.Dense(100)(z)\n",
        "z = tf.keras.layers.Activation('relu')(z)\n",
        "z = tf.keras.layers.Dense(60)(z)\n",
        "z = tf.keras.layers.Activation('relu')(z)\n",
        "z = tf.keras.layers.Dense(30)(z)\n",
        "z = tf.keras.layers.Activation('relu')(z)\n",
        "z = tf.keras.layers.Dense(nb_classes)(z)\n",
        "output_layer = tf.keras.layers.Activation('softmax')(z)\n",
        "\n",
        "model_relu = tf.keras.models.Model(input_layer, output_layer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pU3jqSLsSrqu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "45575eb8-93f1-4178-f803-ccb1860e5bf7"
      },
      "source": [
        "model_relu.summary()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_7 (InputLayer)         [(None, 784)]             0         \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 200)               157000    \n",
            "_________________________________________________________________\n",
            "activation_28 (Activation)   (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_29 (Dense)             (None, 100)               20100     \n",
            "_________________________________________________________________\n",
            "activation_29 (Activation)   (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_30 (Dense)             (None, 60)                6060      \n",
            "_________________________________________________________________\n",
            "activation_30 (Activation)   (None, 60)                0         \n",
            "_________________________________________________________________\n",
            "dense_31 (Dense)             (None, 30)                1830      \n",
            "_________________________________________________________________\n",
            "activation_31 (Activation)   (None, 30)                0         \n",
            "_________________________________________________________________\n",
            "dense_32 (Dense)             (None, 10)                310       \n",
            "_________________________________________________________________\n",
            "activation_32 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 185,300\n",
            "Trainable params: 185,300\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIZmznbMS1yl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_relu.compile(loss='categorical_crossentropy', optimizer=\"SGD\", metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQHkMXQmS1hx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "eaefe466-7850-44f3-e4a7-7ea5d0ffe2a7"
      },
      "source": [
        "history2 = model_relu.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=100)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            "60000/60000 [==============================] - 8s 131us/sample - loss: 0.7224 - acc: 0.7777 - val_loss: 0.2774 - val_acc: 0.9181\n",
            "Epoch 2/100\n",
            "60000/60000 [==============================] - 7s 124us/sample - loss: 0.2429 - acc: 0.9289 - val_loss: 0.1956 - val_acc: 0.9397\n",
            "Epoch 3/100\n",
            "60000/60000 [==============================] - 8s 131us/sample - loss: 0.1776 - acc: 0.9480 - val_loss: 0.1644 - val_acc: 0.9514\n",
            "Epoch 4/100\n",
            "60000/60000 [==============================] - 7s 125us/sample - loss: 0.1421 - acc: 0.9581 - val_loss: 0.1367 - val_acc: 0.9607\n",
            "Epoch 5/100\n",
            "60000/60000 [==============================] - 7s 124us/sample - loss: 0.1184 - acc: 0.9651 - val_loss: 0.1182 - val_acc: 0.9647\n",
            "Epoch 6/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 0.1003 - acc: 0.9703 - val_loss: 0.1227 - val_acc: 0.9658\n",
            "Epoch 7/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 0.0874 - acc: 0.9748 - val_loss: 0.1012 - val_acc: 0.9711\n",
            "Epoch 8/100\n",
            "60000/60000 [==============================] - 7s 122us/sample - loss: 0.0764 - acc: 0.9774 - val_loss: 0.1008 - val_acc: 0.9706\n",
            "Epoch 9/100\n",
            "60000/60000 [==============================] - 7s 124us/sample - loss: 0.0668 - acc: 0.9804 - val_loss: 0.0918 - val_acc: 0.9714\n",
            "Epoch 10/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 0.0595 - acc: 0.9819 - val_loss: 0.0976 - val_acc: 0.9711\n",
            "Epoch 11/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 0.0524 - acc: 0.9840 - val_loss: 0.0865 - val_acc: 0.9738\n",
            "Epoch 12/100\n",
            "60000/60000 [==============================] - 7s 124us/sample - loss: 0.0462 - acc: 0.9870 - val_loss: 0.0884 - val_acc: 0.9735\n",
            "Epoch 13/100\n",
            "60000/60000 [==============================] - 7s 124us/sample - loss: 0.0414 - acc: 0.9880 - val_loss: 0.0879 - val_acc: 0.9739\n",
            "Epoch 14/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 0.0371 - acc: 0.9893 - val_loss: 0.0844 - val_acc: 0.9741\n",
            "Epoch 15/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 0.0328 - acc: 0.9909 - val_loss: 0.0876 - val_acc: 0.9741\n",
            "Epoch 16/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 0.0292 - acc: 0.9914 - val_loss: 0.0837 - val_acc: 0.9749\n",
            "Epoch 17/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 0.0263 - acc: 0.9927 - val_loss: 0.0814 - val_acc: 0.9772\n",
            "Epoch 18/100\n",
            "60000/60000 [==============================] - 8s 128us/sample - loss: 0.0231 - acc: 0.9936 - val_loss: 0.0826 - val_acc: 0.9764\n",
            "Epoch 19/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 0.0208 - acc: 0.9948 - val_loss: 0.0821 - val_acc: 0.9750\n",
            "Epoch 20/100\n",
            "60000/60000 [==============================] - 7s 124us/sample - loss: 0.0179 - acc: 0.9957 - val_loss: 0.0929 - val_acc: 0.9740\n",
            "Epoch 21/100\n",
            "60000/60000 [==============================] - 7s 122us/sample - loss: 0.0162 - acc: 0.9962 - val_loss: 0.0888 - val_acc: 0.9755\n",
            "Epoch 22/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 0.0139 - acc: 0.9967 - val_loss: 0.0823 - val_acc: 0.9772\n",
            "Epoch 23/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 0.0120 - acc: 0.9974 - val_loss: 0.0902 - val_acc: 0.9744\n",
            "Epoch 24/100\n",
            "60000/60000 [==============================] - 7s 124us/sample - loss: 0.0105 - acc: 0.9979 - val_loss: 0.0852 - val_acc: 0.9769\n",
            "Epoch 25/100\n",
            "60000/60000 [==============================] - 7s 124us/sample - loss: 0.0089 - acc: 0.9983 - val_loss: 0.0872 - val_acc: 0.9766\n",
            "Epoch 26/100\n",
            "60000/60000 [==============================] - 7s 124us/sample - loss: 0.0080 - acc: 0.9987 - val_loss: 0.0871 - val_acc: 0.9774\n",
            "Epoch 27/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 0.0065 - acc: 0.9991 - val_loss: 0.0908 - val_acc: 0.9766\n",
            "Epoch 28/100\n",
            "60000/60000 [==============================] - 7s 122us/sample - loss: 0.0059 - acc: 0.9992 - val_loss: 0.0927 - val_acc: 0.9762\n",
            "Epoch 29/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 0.0052 - acc: 0.9992 - val_loss: 0.0885 - val_acc: 0.9775\n",
            "Epoch 30/100\n",
            "60000/60000 [==============================] - 7s 124us/sample - loss: 0.0044 - acc: 0.9996 - val_loss: 0.0909 - val_acc: 0.9764\n",
            "Epoch 31/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 0.0037 - acc: 0.9998 - val_loss: 0.0920 - val_acc: 0.9771\n",
            "Epoch 32/100\n",
            "60000/60000 [==============================] - 7s 122us/sample - loss: 0.0034 - acc: 0.9998 - val_loss: 0.0919 - val_acc: 0.9776\n",
            "Epoch 33/100\n",
            "60000/60000 [==============================] - 7s 122us/sample - loss: 0.0029 - acc: 0.9999 - val_loss: 0.0931 - val_acc: 0.9768\n",
            "Epoch 34/100\n",
            "60000/60000 [==============================] - 7s 122us/sample - loss: 0.0026 - acc: 0.9999 - val_loss: 0.0936 - val_acc: 0.9773\n",
            "Epoch 35/100\n",
            "60000/60000 [==============================] - 7s 124us/sample - loss: 0.0023 - acc: 0.9999 - val_loss: 0.0932 - val_acc: 0.9774\n",
            "Epoch 36/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0965 - val_acc: 0.9774\n",
            "Epoch 37/100\n",
            "60000/60000 [==============================] - 7s 121us/sample - loss: 0.0022 - acc: 0.9999 - val_loss: 0.0976 - val_acc: 0.9765\n",
            "Epoch 38/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 0.0022 - acc: 0.9999 - val_loss: 0.0960 - val_acc: 0.9778\n",
            "Epoch 39/100\n",
            "60000/60000 [==============================] - 7s 122us/sample - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0972 - val_acc: 0.9772\n",
            "Epoch 40/100\n",
            "60000/60000 [==============================] - 7s 122us/sample - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0970 - val_acc: 0.9777\n",
            "Epoch 41/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0978 - val_acc: 0.9775\n",
            "Epoch 42/100\n",
            "60000/60000 [==============================] - 8s 131us/sample - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0993 - val_acc: 0.9778\n",
            "Epoch 43/100\n",
            "60000/60000 [==============================] - 7s 122us/sample - loss: 0.0014 - acc: 1.0000 - val_loss: 0.1005 - val_acc: 0.9775\n",
            "Epoch 44/100\n",
            "60000/60000 [==============================] - 7s 125us/sample - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0998 - val_acc: 0.9778\n",
            "Epoch 45/100\n",
            "60000/60000 [==============================] - 8s 133us/sample - loss: 0.0012 - acc: 1.0000 - val_loss: 0.1010 - val_acc: 0.9782\n",
            "Epoch 46/100\n",
            "60000/60000 [==============================] - 7s 124us/sample - loss: 0.0012 - acc: 1.0000 - val_loss: 0.1020 - val_acc: 0.9776\n",
            "Epoch 47/100\n",
            "60000/60000 [==============================] - 7s 124us/sample - loss: 0.0011 - acc: 1.0000 - val_loss: 0.1013 - val_acc: 0.9777\n",
            "Epoch 48/100\n",
            "60000/60000 [==============================] - 7s 121us/sample - loss: 0.0011 - acc: 1.0000 - val_loss: 0.1031 - val_acc: 0.9777\n",
            "Epoch 49/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 0.0010 - acc: 1.0000 - val_loss: 0.1035 - val_acc: 0.9776\n",
            "Epoch 50/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 9.6468e-04 - acc: 1.0000 - val_loss: 0.1036 - val_acc: 0.9773\n",
            "Epoch 51/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 9.2026e-04 - acc: 1.0000 - val_loss: 0.1042 - val_acc: 0.9774\n",
            "Epoch 52/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 8.7089e-04 - acc: 1.0000 - val_loss: 0.1054 - val_acc: 0.9780\n",
            "Epoch 53/100\n",
            "60000/60000 [==============================] - 7s 122us/sample - loss: 8.3997e-04 - acc: 1.0000 - val_loss: 0.1047 - val_acc: 0.9777\n",
            "Epoch 54/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 7.8978e-04 - acc: 1.0000 - val_loss: 0.1064 - val_acc: 0.9775\n",
            "Epoch 55/100\n",
            "60000/60000 [==============================] - 7s 124us/sample - loss: 7.5994e-04 - acc: 1.0000 - val_loss: 0.1059 - val_acc: 0.9775\n",
            "Epoch 56/100\n",
            "60000/60000 [==============================] - 7s 124us/sample - loss: 7.0927e-04 - acc: 1.0000 - val_loss: 0.1066 - val_acc: 0.9779\n",
            "Epoch 57/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 6.7817e-04 - acc: 1.0000 - val_loss: 0.1072 - val_acc: 0.9774\n",
            "Epoch 58/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 6.2414e-04 - acc: 1.0000 - val_loss: 0.1073 - val_acc: 0.9779\n",
            "Epoch 59/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 5.8789e-04 - acc: 1.0000 - val_loss: 0.1085 - val_acc: 0.9781\n",
            "Epoch 60/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 5.5128e-04 - acc: 1.0000 - val_loss: 0.1075 - val_acc: 0.9777\n",
            "Epoch 61/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 5.2889e-04 - acc: 1.0000 - val_loss: 0.1087 - val_acc: 0.9779\n",
            "Epoch 62/100\n",
            "60000/60000 [==============================] - 7s 122us/sample - loss: 5.0479e-04 - acc: 1.0000 - val_loss: 0.1093 - val_acc: 0.9773\n",
            "Epoch 63/100\n",
            "60000/60000 [==============================] - 7s 122us/sample - loss: 4.8941e-04 - acc: 1.0000 - val_loss: 0.1091 - val_acc: 0.9782\n",
            "Epoch 64/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 4.6937e-04 - acc: 1.0000 - val_loss: 0.1093 - val_acc: 0.9777\n",
            "Epoch 65/100\n",
            "60000/60000 [==============================] - 7s 122us/sample - loss: 4.5257e-04 - acc: 1.0000 - val_loss: 0.1106 - val_acc: 0.9780\n",
            "Epoch 66/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 4.3637e-04 - acc: 1.0000 - val_loss: 0.1110 - val_acc: 0.9778\n",
            "Epoch 67/100\n",
            "60000/60000 [==============================] - 7s 124us/sample - loss: 4.2272e-04 - acc: 1.0000 - val_loss: 0.1109 - val_acc: 0.9777\n",
            "Epoch 68/100\n",
            "60000/60000 [==============================] - 7s 122us/sample - loss: 4.1207e-04 - acc: 1.0000 - val_loss: 0.1113 - val_acc: 0.9775\n",
            "Epoch 69/100\n",
            "60000/60000 [==============================] - 7s 122us/sample - loss: 3.9513e-04 - acc: 1.0000 - val_loss: 0.1123 - val_acc: 0.9771\n",
            "Epoch 70/100\n",
            "60000/60000 [==============================] - 7s 124us/sample - loss: 3.8713e-04 - acc: 1.0000 - val_loss: 0.1120 - val_acc: 0.9776\n",
            "Epoch 71/100\n",
            "60000/60000 [==============================] - 7s 124us/sample - loss: 3.7454e-04 - acc: 1.0000 - val_loss: 0.1125 - val_acc: 0.9779\n",
            "Epoch 72/100\n",
            "60000/60000 [==============================] - 7s 122us/sample - loss: 3.6341e-04 - acc: 1.0000 - val_loss: 0.1134 - val_acc: 0.9779\n",
            "Epoch 73/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 3.5481e-04 - acc: 1.0000 - val_loss: 0.1128 - val_acc: 0.9776\n",
            "Epoch 74/100\n",
            "60000/60000 [==============================] - 7s 124us/sample - loss: 3.4496e-04 - acc: 1.0000 - val_loss: 0.1133 - val_acc: 0.9777\n",
            "Epoch 75/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 3.3545e-04 - acc: 1.0000 - val_loss: 0.1135 - val_acc: 0.9774\n",
            "Epoch 76/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 3.2599e-04 - acc: 1.0000 - val_loss: 0.1134 - val_acc: 0.9778\n",
            "Epoch 77/100\n",
            "60000/60000 [==============================] - 7s 122us/sample - loss: 3.1762e-04 - acc: 1.0000 - val_loss: 0.1134 - val_acc: 0.9776\n",
            "Epoch 78/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 3.1004e-04 - acc: 1.0000 - val_loss: 0.1150 - val_acc: 0.9776\n",
            "Epoch 79/100\n",
            "60000/60000 [==============================] - 7s 124us/sample - loss: 3.0504e-04 - acc: 1.0000 - val_loss: 0.1143 - val_acc: 0.9779\n",
            "Epoch 80/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 2.9638e-04 - acc: 1.0000 - val_loss: 0.1150 - val_acc: 0.9779\n",
            "Epoch 81/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 2.8914e-04 - acc: 1.0000 - val_loss: 0.1154 - val_acc: 0.9778\n",
            "Epoch 82/100\n",
            "60000/60000 [==============================] - 7s 124us/sample - loss: 2.8306e-04 - acc: 1.0000 - val_loss: 0.1151 - val_acc: 0.9781\n",
            "Epoch 83/100\n",
            "60000/60000 [==============================] - 8s 128us/sample - loss: 2.7669e-04 - acc: 1.0000 - val_loss: 0.1156 - val_acc: 0.9779\n",
            "Epoch 84/100\n",
            "60000/60000 [==============================] - 8s 126us/sample - loss: 2.7045e-04 - acc: 1.0000 - val_loss: 0.1162 - val_acc: 0.9778\n",
            "Epoch 85/100\n",
            "60000/60000 [==============================] - 7s 124us/sample - loss: 2.6513e-04 - acc: 1.0000 - val_loss: 0.1161 - val_acc: 0.9778\n",
            "Epoch 86/100\n",
            "60000/60000 [==============================] - 8s 126us/sample - loss: 2.5928e-04 - acc: 1.0000 - val_loss: 0.1168 - val_acc: 0.9778\n",
            "Epoch 87/100\n",
            "60000/60000 [==============================] - 8s 133us/sample - loss: 2.5355e-04 - acc: 1.0000 - val_loss: 0.1170 - val_acc: 0.9779\n",
            "Epoch 88/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 2.4807e-04 - acc: 1.0000 - val_loss: 0.1174 - val_acc: 0.9778\n",
            "Epoch 89/100\n",
            "60000/60000 [==============================] - 7s 122us/sample - loss: 2.4369e-04 - acc: 1.0000 - val_loss: 0.1174 - val_acc: 0.9779\n",
            "Epoch 90/100\n",
            "60000/60000 [==============================] - 7s 124us/sample - loss: 2.3884e-04 - acc: 1.0000 - val_loss: 0.1183 - val_acc: 0.9779\n",
            "Epoch 91/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 2.3370e-04 - acc: 1.0000 - val_loss: 0.1180 - val_acc: 0.9778\n",
            "Epoch 92/100\n",
            "60000/60000 [==============================] - 7s 124us/sample - loss: 2.3011e-04 - acc: 1.0000 - val_loss: 0.1187 - val_acc: 0.9778\n",
            "Epoch 93/100\n",
            "60000/60000 [==============================] - 7s 122us/sample - loss: 2.2553e-04 - acc: 1.0000 - val_loss: 0.1178 - val_acc: 0.9778\n",
            "Epoch 94/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 2.2078e-04 - acc: 1.0000 - val_loss: 0.1183 - val_acc: 0.9778\n",
            "Epoch 95/100\n",
            "60000/60000 [==============================] - 7s 124us/sample - loss: 2.1677e-04 - acc: 1.0000 - val_loss: 0.1184 - val_acc: 0.9776\n",
            "Epoch 96/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 2.1327e-04 - acc: 1.0000 - val_loss: 0.1184 - val_acc: 0.9778\n",
            "Epoch 97/100\n",
            "60000/60000 [==============================] - 7s 124us/sample - loss: 2.0982e-04 - acc: 1.0000 - val_loss: 0.1191 - val_acc: 0.9779\n",
            "Epoch 98/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 2.0526e-04 - acc: 1.0000 - val_loss: 0.1194 - val_acc: 0.9780\n",
            "Epoch 99/100\n",
            "60000/60000 [==============================] - 7s 124us/sample - loss: 2.0230e-04 - acc: 1.0000 - val_loss: 0.1196 - val_acc: 0.9779\n",
            "Epoch 100/100\n",
            "60000/60000 [==============================] - 7s 125us/sample - loss: 1.9887e-04 - acc: 1.0000 - val_loss: 0.1199 - val_acc: 0.9779\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rregGf0WTHby",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "1e918286-e0bb-40da-e9fe-9cd88cf6eb88"
      },
      "source": [
        "acc = history2.history['acc']\n",
        "val_acc = history2.history['val_acc']\n",
        "epochs   = range(len(acc)) # Get number of epochs\n",
        "\n",
        "plt.plot(epochs, acc, 'b')\n",
        "plt.plot(epochs, val_acc, 'r')\n",
        "plt.title('Training accuracy')\n",
        "plt.figure()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wt2DrSzRX78Y",
        "colab_type": "text"
      },
      "source": [
        "# With Dropout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNSNmGRWX-A9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_layer = tf.keras.layers.Input(shape=(784,))\n",
        "z = tf.keras.layers.Dense(200)(input_layer)\n",
        "z = tf.keras.layers.Activation('relu')(z)\n",
        "z = tf.keras.layers.Dropout(rate=0.4)(z)\n",
        "z = tf.keras.layers.Dense(100)(z)\n",
        "z = tf.keras.layers.Activation('relu')(z)\n",
        "z = tf.keras.layers.Dropout(rate=0.4)(z)\n",
        "z = tf.keras.layers.Dense(60)(z)\n",
        "z = tf.keras.layers.Activation('relu')(z)\n",
        "z = tf.keras.layers.Dropout(rate=0.4)(z)\n",
        "z = tf.keras.layers.Dense(30)(z)\n",
        "z = tf.keras.layers.Activation('relu')(z)\n",
        "z = tf.keras.layers.Dropout(rate=0.4)(z)\n",
        "z = tf.keras.layers.Dense(nb_classes)(z)\n",
        "output_layer = tf.keras.layers.Activation('softmax')(z)\n",
        "\n",
        "model_relu_dropout = tf.keras.models.Model(input_layer, output_layer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrnssiKdZ9QY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "outputId": "28cff070-dbbe-4c2f-b991-a4d55b45f88e"
      },
      "source": [
        "model_relu_dropout.summary()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_8 (InputLayer)         [(None, 784)]             0         \n",
            "_________________________________________________________________\n",
            "dense_33 (Dense)             (None, 200)               157000    \n",
            "_________________________________________________________________\n",
            "activation_33 (Activation)   (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_34 (Dense)             (None, 100)               20100     \n",
            "_________________________________________________________________\n",
            "activation_34 (Activation)   (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_35 (Dense)             (None, 60)                6060      \n",
            "_________________________________________________________________\n",
            "activation_35 (Activation)   (None, 60)                0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 60)                0         \n",
            "_________________________________________________________________\n",
            "dense_36 (Dense)             (None, 30)                1830      \n",
            "_________________________________________________________________\n",
            "activation_36 (Activation)   (None, 30)                0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 30)                0         \n",
            "_________________________________________________________________\n",
            "dense_37 (Dense)             (None, 10)                310       \n",
            "_________________________________________________________________\n",
            "activation_37 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 185,300\n",
            "Trainable params: 185,300\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNqKte34aCVI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_relu_dropout.compile(loss='categorical_crossentropy', optimizer=\"SGD\", metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbOXKWWnaNTT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "28021ef0-3bbf-4c60-a67b-080cb6ebdef7"
      },
      "source": [
        "history3 = model_relu_dropout.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=100)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            "60000/60000 [==============================] - 9s 146us/sample - loss: 1.7751 - acc: 0.3645 - val_loss: 0.7887 - val_acc: 0.7827\n",
            "Epoch 2/100\n",
            "60000/60000 [==============================] - 8s 139us/sample - loss: 0.9943 - acc: 0.6572 - val_loss: 0.5003 - val_acc: 0.8559\n",
            "Epoch 3/100\n",
            "60000/60000 [==============================] - 8s 140us/sample - loss: 0.7445 - acc: 0.7566 - val_loss: 0.3631 - val_acc: 0.9155\n",
            "Epoch 4/100\n",
            "60000/60000 [==============================] - 8s 138us/sample - loss: 0.6104 - acc: 0.8163 - val_loss: 0.2780 - val_acc: 0.9293\n",
            "Epoch 5/100\n",
            "60000/60000 [==============================] - 8s 138us/sample - loss: 0.5167 - acc: 0.8531 - val_loss: 0.2276 - val_acc: 0.9425\n",
            "Epoch 6/100\n",
            "60000/60000 [==============================] - 8s 140us/sample - loss: 0.4533 - acc: 0.8745 - val_loss: 0.2008 - val_acc: 0.9473\n",
            "Epoch 7/100\n",
            "60000/60000 [==============================] - 8s 139us/sample - loss: 0.4115 - acc: 0.8901 - val_loss: 0.1858 - val_acc: 0.9501\n",
            "Epoch 8/100\n",
            "60000/60000 [==============================] - 8s 138us/sample - loss: 0.3759 - acc: 0.9022 - val_loss: 0.1723 - val_acc: 0.9554\n",
            "Epoch 9/100\n",
            "60000/60000 [==============================] - 8s 138us/sample - loss: 0.3463 - acc: 0.9094 - val_loss: 0.1587 - val_acc: 0.9569\n",
            "Epoch 10/100\n",
            "60000/60000 [==============================] - 8s 138us/sample - loss: 0.3287 - acc: 0.9152 - val_loss: 0.1592 - val_acc: 0.9584\n",
            "Epoch 11/100\n",
            "60000/60000 [==============================] - 8s 140us/sample - loss: 0.3117 - acc: 0.9210 - val_loss: 0.1464 - val_acc: 0.9623\n",
            "Epoch 12/100\n",
            "60000/60000 [==============================] - 8s 138us/sample - loss: 0.2961 - acc: 0.9244 - val_loss: 0.1425 - val_acc: 0.9627\n",
            "Epoch 13/100\n",
            "60000/60000 [==============================] - 8s 139us/sample - loss: 0.2780 - acc: 0.9291 - val_loss: 0.1343 - val_acc: 0.9649\n",
            "Epoch 14/100\n",
            "60000/60000 [==============================] - 8s 138us/sample - loss: 0.2701 - acc: 0.9314 - val_loss: 0.1360 - val_acc: 0.9643\n",
            "Epoch 15/100\n",
            "60000/60000 [==============================] - 8s 138us/sample - loss: 0.2574 - acc: 0.9354 - val_loss: 0.1332 - val_acc: 0.9673\n",
            "Epoch 16/100\n",
            "60000/60000 [==============================] - 8s 138us/sample - loss: 0.2523 - acc: 0.9374 - val_loss: 0.1264 - val_acc: 0.9678\n",
            "Epoch 17/100\n",
            "60000/60000 [==============================] - 8s 139us/sample - loss: 0.2447 - acc: 0.9380 - val_loss: 0.1269 - val_acc: 0.9682\n",
            "Epoch 18/100\n",
            "60000/60000 [==============================] - 8s 139us/sample - loss: 0.2328 - acc: 0.9414 - val_loss: 0.1212 - val_acc: 0.9700\n",
            "Epoch 19/100\n",
            "60000/60000 [==============================] - 8s 139us/sample - loss: 0.2283 - acc: 0.9421 - val_loss: 0.1170 - val_acc: 0.9715\n",
            "Epoch 20/100\n",
            "60000/60000 [==============================] - 8s 139us/sample - loss: 0.2163 - acc: 0.9457 - val_loss: 0.1174 - val_acc: 0.9717\n",
            "Epoch 21/100\n",
            "60000/60000 [==============================] - 8s 138us/sample - loss: 0.2189 - acc: 0.9455 - val_loss: 0.1189 - val_acc: 0.9706\n",
            "Epoch 22/100\n",
            "60000/60000 [==============================] - 8s 137us/sample - loss: 0.2101 - acc: 0.9469 - val_loss: 0.1136 - val_acc: 0.9725\n",
            "Epoch 23/100\n",
            "60000/60000 [==============================] - 8s 139us/sample - loss: 0.2044 - acc: 0.9485 - val_loss: 0.1172 - val_acc: 0.9721\n",
            "Epoch 24/100\n",
            "60000/60000 [==============================] - 8s 138us/sample - loss: 0.2068 - acc: 0.9496 - val_loss: 0.1147 - val_acc: 0.9731\n",
            "Epoch 25/100\n",
            "60000/60000 [==============================] - 8s 139us/sample - loss: 0.1932 - acc: 0.9523 - val_loss: 0.1103 - val_acc: 0.9740\n",
            "Epoch 26/100\n",
            "60000/60000 [==============================] - 8s 140us/sample - loss: 0.1896 - acc: 0.9531 - val_loss: 0.1122 - val_acc: 0.9736\n",
            "Epoch 27/100\n",
            "60000/60000 [==============================] - 8s 141us/sample - loss: 0.1896 - acc: 0.9530 - val_loss: 0.1122 - val_acc: 0.9736\n",
            "Epoch 28/100\n",
            "60000/60000 [==============================] - 8s 139us/sample - loss: 0.1853 - acc: 0.9540 - val_loss: 0.1135 - val_acc: 0.9732\n",
            "Epoch 29/100\n",
            "60000/60000 [==============================] - 8s 140us/sample - loss: 0.1821 - acc: 0.9546 - val_loss: 0.1045 - val_acc: 0.9761\n",
            "Epoch 30/100\n",
            "60000/60000 [==============================] - 8s 139us/sample - loss: 0.1762 - acc: 0.9574 - val_loss: 0.1138 - val_acc: 0.9737\n",
            "Epoch 31/100\n",
            "60000/60000 [==============================] - 8s 140us/sample - loss: 0.1778 - acc: 0.9570 - val_loss: 0.1048 - val_acc: 0.9757\n",
            "Epoch 32/100\n",
            "60000/60000 [==============================] - 8s 140us/sample - loss: 0.1692 - acc: 0.9582 - val_loss: 0.1156 - val_acc: 0.9739\n",
            "Epoch 33/100\n",
            "60000/60000 [==============================] - 9s 145us/sample - loss: 0.1622 - acc: 0.9581 - val_loss: 0.1110 - val_acc: 0.9747\n",
            "Epoch 34/100\n",
            "60000/60000 [==============================] - 8s 138us/sample - loss: 0.1673 - acc: 0.9588 - val_loss: 0.1105 - val_acc: 0.9746\n",
            "Epoch 35/100\n",
            "60000/60000 [==============================] - 8s 139us/sample - loss: 0.1662 - acc: 0.9598 - val_loss: 0.1060 - val_acc: 0.9760\n",
            "Epoch 36/100\n",
            "60000/60000 [==============================] - 8s 139us/sample - loss: 0.1614 - acc: 0.9597 - val_loss: 0.1094 - val_acc: 0.9757\n",
            "Epoch 37/100\n",
            "60000/60000 [==============================] - 9s 149us/sample - loss: 0.1597 - acc: 0.9604 - val_loss: 0.1073 - val_acc: 0.9758\n",
            "Epoch 38/100\n",
            "60000/60000 [==============================] - 9s 142us/sample - loss: 0.1601 - acc: 0.9605 - val_loss: 0.1065 - val_acc: 0.9744\n",
            "Epoch 39/100\n",
            "60000/60000 [==============================] - 8s 140us/sample - loss: 0.1578 - acc: 0.9614 - val_loss: 0.1034 - val_acc: 0.9760\n",
            "Epoch 40/100\n",
            "60000/60000 [==============================] - 8s 139us/sample - loss: 0.1520 - acc: 0.9631 - val_loss: 0.1099 - val_acc: 0.9758\n",
            "Epoch 41/100\n",
            "60000/60000 [==============================] - 8s 140us/sample - loss: 0.1521 - acc: 0.9621 - val_loss: 0.1108 - val_acc: 0.9757\n",
            "Epoch 42/100\n",
            "60000/60000 [==============================] - 8s 139us/sample - loss: 0.1457 - acc: 0.9636 - val_loss: 0.1107 - val_acc: 0.9769\n",
            "Epoch 43/100\n",
            "60000/60000 [==============================] - 8s 139us/sample - loss: 0.1436 - acc: 0.9643 - val_loss: 0.1148 - val_acc: 0.9764\n",
            "Epoch 44/100\n",
            "60000/60000 [==============================] - 8s 139us/sample - loss: 0.1414 - acc: 0.9652 - val_loss: 0.1073 - val_acc: 0.9768\n",
            "Epoch 45/100\n",
            "60000/60000 [==============================] - 8s 137us/sample - loss: 0.1418 - acc: 0.9651 - val_loss: 0.1110 - val_acc: 0.9776\n",
            "Epoch 46/100\n",
            "60000/60000 [==============================] - 8s 138us/sample - loss: 0.1448 - acc: 0.9650 - val_loss: 0.1047 - val_acc: 0.9767\n",
            "Epoch 47/100\n",
            "60000/60000 [==============================] - 8s 138us/sample - loss: 0.1340 - acc: 0.9666 - val_loss: 0.1110 - val_acc: 0.9767\n",
            "Epoch 48/100\n",
            "60000/60000 [==============================] - 8s 139us/sample - loss: 0.1362 - acc: 0.9668 - val_loss: 0.1101 - val_acc: 0.9773\n",
            "Epoch 49/100\n",
            "60000/60000 [==============================] - 8s 140us/sample - loss: 0.1388 - acc: 0.9662 - val_loss: 0.1101 - val_acc: 0.9774\n",
            "Epoch 50/100\n",
            "60000/60000 [==============================] - 8s 139us/sample - loss: 0.1309 - acc: 0.9670 - val_loss: 0.1016 - val_acc: 0.9775\n",
            "Epoch 51/100\n",
            "60000/60000 [==============================] - 8s 139us/sample - loss: 0.1350 - acc: 0.9673 - val_loss: 0.1121 - val_acc: 0.9760\n",
            "Epoch 52/100\n",
            "60000/60000 [==============================] - 8s 139us/sample - loss: 0.1301 - acc: 0.9680 - val_loss: 0.1058 - val_acc: 0.9781\n",
            "Epoch 53/100\n",
            "60000/60000 [==============================] - 8s 139us/sample - loss: 0.1303 - acc: 0.9672 - val_loss: 0.1128 - val_acc: 0.9763\n",
            "Epoch 54/100\n",
            "60000/60000 [==============================] - 8s 138us/sample - loss: 0.1301 - acc: 0.9680 - val_loss: 0.1089 - val_acc: 0.9771\n",
            "Epoch 55/100\n",
            "60000/60000 [==============================] - 8s 138us/sample - loss: 0.1252 - acc: 0.9682 - val_loss: 0.1065 - val_acc: 0.9775\n",
            "Epoch 56/100\n",
            "60000/60000 [==============================] - 8s 138us/sample - loss: 0.1223 - acc: 0.9694 - val_loss: 0.1121 - val_acc: 0.9769\n",
            "Epoch 57/100\n",
            "60000/60000 [==============================] - 8s 138us/sample - loss: 0.1242 - acc: 0.9686 - val_loss: 0.1129 - val_acc: 0.9779\n",
            "Epoch 58/100\n",
            "60000/60000 [==============================] - 8s 139us/sample - loss: 0.1257 - acc: 0.9691 - val_loss: 0.1146 - val_acc: 0.9761\n",
            "Epoch 59/100\n",
            "60000/60000 [==============================] - 8s 139us/sample - loss: 0.1260 - acc: 0.9693 - val_loss: 0.1021 - val_acc: 0.9785\n",
            "Epoch 60/100\n",
            "60000/60000 [==============================] - 8s 138us/sample - loss: 0.1245 - acc: 0.9692 - val_loss: 0.1095 - val_acc: 0.9781\n",
            "Epoch 61/100\n",
            "60000/60000 [==============================] - 8s 139us/sample - loss: 0.1195 - acc: 0.9709 - val_loss: 0.1084 - val_acc: 0.9782\n",
            "Epoch 62/100\n",
            "60000/60000 [==============================] - 8s 137us/sample - loss: 0.1174 - acc: 0.9705 - val_loss: 0.0978 - val_acc: 0.9798\n",
            "Epoch 63/100\n",
            "60000/60000 [==============================] - 8s 138us/sample - loss: 0.1203 - acc: 0.9704 - val_loss: 0.1054 - val_acc: 0.9779\n",
            "Epoch 64/100\n",
            "60000/60000 [==============================] - 8s 137us/sample - loss: 0.1159 - acc: 0.9717 - val_loss: 0.1081 - val_acc: 0.9777\n",
            "Epoch 65/100\n",
            "60000/60000 [==============================] - 8s 138us/sample - loss: 0.1160 - acc: 0.9708 - val_loss: 0.1100 - val_acc: 0.9775\n",
            "Epoch 66/100\n",
            "60000/60000 [==============================] - 8s 139us/sample - loss: 0.1139 - acc: 0.9711 - val_loss: 0.1056 - val_acc: 0.9795\n",
            "Epoch 67/100\n",
            "60000/60000 [==============================] - 8s 137us/sample - loss: 0.1106 - acc: 0.9729 - val_loss: 0.1055 - val_acc: 0.9788\n",
            "Epoch 68/100\n",
            "60000/60000 [==============================] - 8s 137us/sample - loss: 0.1118 - acc: 0.9717 - val_loss: 0.1048 - val_acc: 0.9784\n",
            "Epoch 69/100\n",
            "60000/60000 [==============================] - 8s 140us/sample - loss: 0.1108 - acc: 0.9721 - val_loss: 0.1112 - val_acc: 0.9778\n",
            "Epoch 70/100\n",
            "60000/60000 [==============================] - 8s 141us/sample - loss: 0.1161 - acc: 0.9711 - val_loss: 0.1152 - val_acc: 0.9767\n",
            "Epoch 71/100\n",
            "60000/60000 [==============================] - 8s 138us/sample - loss: 0.1117 - acc: 0.9727 - val_loss: 0.1124 - val_acc: 0.9775\n",
            "Epoch 72/100\n",
            "60000/60000 [==============================] - 8s 137us/sample - loss: 0.1102 - acc: 0.9723 - val_loss: 0.1120 - val_acc: 0.9777\n",
            "Epoch 73/100\n",
            "60000/60000 [==============================] - 8s 138us/sample - loss: 0.1083 - acc: 0.9732 - val_loss: 0.1068 - val_acc: 0.9780\n",
            "Epoch 74/100\n",
            "60000/60000 [==============================] - 9s 144us/sample - loss: 0.1087 - acc: 0.9728 - val_loss: 0.1175 - val_acc: 0.9772\n",
            "Epoch 75/100\n",
            "60000/60000 [==============================] - 9s 143us/sample - loss: 0.1069 - acc: 0.9740 - val_loss: 0.1089 - val_acc: 0.9780\n",
            "Epoch 76/100\n",
            "60000/60000 [==============================] - 8s 139us/sample - loss: 0.1055 - acc: 0.9729 - val_loss: 0.1064 - val_acc: 0.9784\n",
            "Epoch 77/100\n",
            "60000/60000 [==============================] - 8s 140us/sample - loss: 0.1065 - acc: 0.9737 - val_loss: 0.1105 - val_acc: 0.9790\n",
            "Epoch 78/100\n",
            "60000/60000 [==============================] - 8s 139us/sample - loss: 0.1032 - acc: 0.9738 - val_loss: 0.1162 - val_acc: 0.9778\n",
            "Epoch 79/100\n",
            "60000/60000 [==============================] - 8s 139us/sample - loss: 0.1039 - acc: 0.9743 - val_loss: 0.1105 - val_acc: 0.9786\n",
            "Epoch 80/100\n",
            "60000/60000 [==============================] - 8s 139us/sample - loss: 0.0998 - acc: 0.9753 - val_loss: 0.1187 - val_acc: 0.9779\n",
            "Epoch 81/100\n",
            "60000/60000 [==============================] - 8s 139us/sample - loss: 0.1032 - acc: 0.9742 - val_loss: 0.1118 - val_acc: 0.9784\n",
            "Epoch 82/100\n",
            "60000/60000 [==============================] - 8s 139us/sample - loss: 0.1033 - acc: 0.9750 - val_loss: 0.1115 - val_acc: 0.9795\n",
            "Epoch 83/100\n",
            "60000/60000 [==============================] - 8s 139us/sample - loss: 0.1021 - acc: 0.9748 - val_loss: 0.1110 - val_acc: 0.9792\n",
            "Epoch 84/100\n",
            "60000/60000 [==============================] - 8s 139us/sample - loss: 0.0987 - acc: 0.9755 - val_loss: 0.1102 - val_acc: 0.9791\n",
            "Epoch 85/100\n",
            "60000/60000 [==============================] - 8s 138us/sample - loss: 0.1003 - acc: 0.9748 - val_loss: 0.1073 - val_acc: 0.9790\n",
            "Epoch 86/100\n",
            "60000/60000 [==============================] - 8s 138us/sample - loss: 0.1006 - acc: 0.9748 - val_loss: 0.1131 - val_acc: 0.9784\n",
            "Epoch 87/100\n",
            "60000/60000 [==============================] - 8s 140us/sample - loss: 0.1019 - acc: 0.9748 - val_loss: 0.1190 - val_acc: 0.9776\n",
            "Epoch 88/100\n",
            "60000/60000 [==============================] - 8s 139us/sample - loss: 0.0997 - acc: 0.9753 - val_loss: 0.1107 - val_acc: 0.9796\n",
            "Epoch 89/100\n",
            "60000/60000 [==============================] - 8s 140us/sample - loss: 0.0951 - acc: 0.9763 - val_loss: 0.1032 - val_acc: 0.9798\n",
            "Epoch 90/100\n",
            "60000/60000 [==============================] - 8s 139us/sample - loss: 0.0997 - acc: 0.9757 - val_loss: 0.1077 - val_acc: 0.9787\n",
            "Epoch 91/100\n",
            "60000/60000 [==============================] - 8s 140us/sample - loss: 0.0956 - acc: 0.9761 - val_loss: 0.1139 - val_acc: 0.9782\n",
            "Epoch 92/100\n",
            "60000/60000 [==============================] - 8s 138us/sample - loss: 0.0943 - acc: 0.9762 - val_loss: 0.1090 - val_acc: 0.9789\n",
            "Epoch 93/100\n",
            "60000/60000 [==============================] - 8s 137us/sample - loss: 0.0957 - acc: 0.9760 - val_loss: 0.1124 - val_acc: 0.9795\n",
            "Epoch 94/100\n",
            "60000/60000 [==============================] - 8s 137us/sample - loss: 0.0971 - acc: 0.9755 - val_loss: 0.1085 - val_acc: 0.9797\n",
            "Epoch 95/100\n",
            "60000/60000 [==============================] - 8s 139us/sample - loss: 0.0900 - acc: 0.9768 - val_loss: 0.1136 - val_acc: 0.9790\n",
            "Epoch 96/100\n",
            "60000/60000 [==============================] - 8s 137us/sample - loss: 0.0869 - acc: 0.9779 - val_loss: 0.1145 - val_acc: 0.9790\n",
            "Epoch 97/100\n",
            "60000/60000 [==============================] - 8s 139us/sample - loss: 0.0945 - acc: 0.9766 - val_loss: 0.1187 - val_acc: 0.9788\n",
            "Epoch 98/100\n",
            "60000/60000 [==============================] - 8s 139us/sample - loss: 0.0907 - acc: 0.9768 - val_loss: 0.1082 - val_acc: 0.9794\n",
            "Epoch 99/100\n",
            "60000/60000 [==============================] - 8s 138us/sample - loss: 0.0919 - acc: 0.9774 - val_loss: 0.1122 - val_acc: 0.9793\n",
            "Epoch 100/100\n",
            "60000/60000 [==============================] - 8s 140us/sample - loss: 0.0895 - acc: 0.9775 - val_loss: 0.1176 - val_acc: 0.9797\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZ8p7oUJahZb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "d3256049-2106-4106-bd03-2b1ce66a830a"
      },
      "source": [
        "acc = history3.history['acc']\n",
        "val_acc = history3.history['val_acc']\n",
        "epochs   = range(len(acc)) # Get number of epochs\n",
        "\n",
        "plt.plot(epochs, acc, 'b')\n",
        "plt.plot(epochs, val_acc, 'r')\n",
        "plt.title('Training accuracy')\n",
        "plt.figure()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XucXHV9//HXZ3ezuW0um2RDbgtJ\nIIBRKGKahxavqA8DbRMVHv1Bi0ILxUcr1V+1WLBKLcVaW6+tFE3VVimCFH3YqPmVagRbKWCCck1C\nCBvIhQ27yWazyWY3e/v8/vjMuJPNziXJ7M6es+/n4zGP2Zk5M+dz5uy85zvf8z3nmLsjIiLpUlXp\nAkREpPwU7iIiKaRwFxFJIYW7iEgKKdxFRFJI4S4ikkIKdxlTzKzazA6b2enlnFZkvDGNc5dTYWaH\nc25OAY4C/Znb73P3u0a/KhFRuEvZmNkLwHXu/uMC09S4e9/oVZVMep/kVKlbRkaUmd1mZt82s7vN\n7BBwlZm9zsweMbN2M2s2s38wswmZ6WvMzM1sceb2v2Ue/39mdsjMHjazJSc6bebxS8xsm5kdNLN/\nNLOHzOyaPHXnrTHz+Hlm9mMzazOzvWb2kZyaPm5mz5tZh5ltMrMFZnaWmfmQefwsO38zu87M/jsz\nnzbgY2a2zMweyMxjn5ndaWYzcp5/hpl9z8xaM49/0cwmZWp+Rc50883siJnNPvk1KUmjcJfR8C7g\nW8AM4NtAH/BBYA5wEbAKeF+B5/8u8HFgFrAT+OsTndbM5gL3Ajdm5rsDWFngdfLWmAnYHwPfB+YD\nZwMPZp53I3B5ZvqZwHVAd4H55PoNYAvQAHwaMOA2YB6wHFiaWTbMrAb4IbAdWAw0Ave6e3dmOa8a\n8p7c7+77S6xDUkDhLqPhZ+7+fXcfcPcud9/o7o+6e5+7NwFrgTcVeP597r7J3XuBu4ALTmLa3wIe\nd/f/yDz2eWBfvhcpUuNqYKe7f9Hdj7p7h7v/PPPYdcBH3f25zPI+7u5thd+eX9np7ne4e3/mfdrm\n7hvcvcfdWzI1Z2t4HfHF8+fu3pmZ/qHMY98AftfMLHP7PcCdJdYgKVFT6QJkXNiVe8PMzgU+C7yG\n2AhbAzxa4Pl7c/4+AtSdxLQLcutwdzez3flepEiNjcDzeZ5a6LFihr5P84B/IH45TCMaY60583nB\n3fsZwt0fMrM+4PVmdgA4nWjlyziilruMhqFb7b8CPA2c5e7TgVuILoiR1Awsyt7ItGoXFpi+UI27\ngDPzPC/fY52Z+U7JuW/ekGmGvk+fJkYfnZep4ZohNZxhZtV56vgm0TXzHqK75mie6SSlFO5SCdOA\ng0BnZsNfof72cvkBcKGZ/Xamv/qDRN/2ydS4DjjdzG4ws4lmNt3Msv33XwVuM7MzLVxgZrOIXxR7\niQ3K1WZ2PXBGkZqnEV8KB82sEfiznMceBvYDf2NmU8xsspldlPP4nUTf/+8SQS/jjMJdKuHDwNXA\nIaKF/O2RnqG7vwz8H+BzRCieCfySaBmfUI3ufhB4O3AZ8DKwjcG+8L8HvgdsADqIvvpJHmOO/xD4\nKNHXfxaFu6IA/pLY6HuQ+EL5Tk4NfcR2hFcQrfidRJhnH38BeAo46u7/W2Q+kkIa5y7jUqY74yXg\ncnf/n0rXMxLM7JtAk7t/otK1yOjTBlUZN8xsFfAI0AXcDPQCPy/4pIQys6XAGuC8StcilaFuGRlP\nXg80ESNO3gG8K40bGs3sU8ATwN+4+85K1yOVoW4ZEZEUUstdRCSFKtbnPmfOHF+8eHGlZi8ikkiP\nPfbYPncvNIwXKCHczezrxJCrFnd/1TCPG/BF4FJij8Br3P0XxV538eLFbNq0qdhkIiKSw8xeLGW6\nUrpl/pU4CFI+lwDLMpfrgTtKmbGIiIycouHu7v8NFDrw0Rrgmx4eAWaa2fxyFSgiIieuHBtUF3Ls\nAY92k+eYHWZ2feb41ptaW1uHm0RERMpgVEfLuPtad1/h7isaGopuDxARkZNUjnDfQxx+NGtR5j4R\nEamQcoT7OuC9mSPgvRY46O7NZXhdERE5SaUMhbwbeDMwJ3Nyg78EJgC4+5eB9cQwyO3EUMjfH6li\nRUSkNEXD3d2vLPK4A+8vW0Ui48XBg3E9dSrU5HwUBwbghRdg82bYsgXq6+E1r4FXvhJqa/O/3ssv\nw8aN0NICs2bFpb4+Xn/KFJg2La5tBM6LMjAAXV3Q0QHt7XGZPBkWL4aZMwenOXAAenujttxl6emB\n/fth16647NsHEyfCpElxXV0NVVXHXtfUwPTpsYwzZ8KMGfEYxDyeegoee2xwnj09MW1jY1waGuL5\n06dDXx+0tUUNBw7Epb0dDh+O5/b2xvs2axbMnh3zyn0fJ0yIS1XV4HvQ0RHTVFXFpasLjhyBzk54\nxzvgwgvLvx5y6KiQEvbuhaefjn+4WbMG7+/pgR074PTT48NaiDs0N8Nzz8WHYdKkuJhBf39c6uth\n6dLBD/aRI7B1awRS9gMyYcLgh/joUXjxxQi7lpYIqunTo5aurvigHD4cYdDSEh/K+nqYNw9OO21w\nPu4xXTZ4jh6NsMnWlf179mx4xSvg3HPj9R95JC6HD8Ov/RpccAEsWBDza22NQOjsjEtfX3zoZ86M\nQNq7F156KWo655x47tKl8MtfwoMPRnBnZevM1jOc2lqYOzfen9rawfeqtjbe950lHCOspibqmzUL\nFi0aDLn29nj/2trivenpicvRo9DdHX9Pnx7znzMn1ltLS7wHHR3xXuUzY0a8H/v3H7NsXlcHkyZh\nhw7FfE5VdXUsy8yZ8T9bjtccIU++MJ3zvzKy4V6xA4etWLHCtYfqScgGaFdXtMKmTo3g2bMngqS5\nOUJl7974UE6ZEpeJEwdbGtXVg/e3t8MPfgA/zxz51gzOPz+CaMsWePzx+GBXVUXgvfKV8aFpaYmA\nGxiI1zOLGjo7iy9DVVW06MygqSmWqRR1dREqAwPH3j9lSnyoGxoi2NvbY/lffjkCN2vatMEW3nCt\nwaqqWK5t2+LLCeIL4nWvi+c+8US0prOvmW3FTZ0al+rqwVZbV1d8wSxcGM/duhWeeSaeW1cHb3gD\nvP71UUe2NZddN9XV8WW6fHl80ezfHy3QX/wiwjTbCs22KHt7Y7l//ddh5UpobKSvpY09T7VxeNcB\nGqYeYdbETmq6DsHBgwwcaMdb91G9J9NKbm2F+nr6Zs+lc9JsmDSJ6kkTqJo4gW6bzOG+SXT2TGBS\n90GmHmlh0uF9dFdNpa2mgZcHGuidMoPJs6dSN3cKPZNnsK9vJi1HZzBwqJOZ7S9Qf3AH9PSyv6qB\nFhroODIBO9BG7eE2ar2b/inTqJ4xjd66ep47ejqbDzXyQmcDk2t6mVbbzRTrprOjn4H+Aarpp5p+\namyAGVN6mVF1iBnezkxvY7bvY85AK/W+nx2+hId6V/Ko/zotzKWXCfRRQz0HaGQXp7OT2exnGoeY\nTgf9VLOf2exnNgeo5wD1tDOTTqbSQy29TKCafuo5wGz2M29yB6edFqu4bqqzr7mXfS/1cLB9gA6m\n0049R2unMX06zJrRz8zpA/TXTuZozVS6qqZyw4cnsnrNyf2CMrPH3H1F0ekU7hXU2xsf+ieeiCDd\nujVavUeOxIe3ry9aSY2NERK7d8eHvKWl8OuaxfMmT47XOnLk2FbM0JbhypWwenX89N+0KVqVTz0V\nwbJyZYTMjh0R9Js3R5hmW3DV1YMt3/nz4eyzYdmymHd3d4Sc+2Bo7dsX4bltWzznla+My4IFsbzZ\nsMq2YGtr4YwzIuymTo3Xyv68nTw5LlVlHtHb1xfLW1sb8839+X30aIT37NnHdqVkuEcWt7TEJNm3\nCKDn0FE6t+6ie95iegZq6O2N0rMvs307PPnk4HdA9vs3+0Mm+/Y1NUV5/f0RLvPnD67qrq74jt28\n+dhVbhYN766u+NeCqG/Rovi+e/bZ+D48UfPmxWtme5iyqqoGe5uqq+MH3LRpcamvj9U9f358t+3Z\nE//aHR3xfs2dG9+/fX2DP7Cy36PTp8OhQ/EDo7392O9597jtHu9HXV1c5s6Nj8/CzN43Bw/Gc2Hw\ne3nixMEfQu6D359HjsT0Bw/G/UuXwplnRi3D9W5l12l1vjPbloHCvdJ6euCnP4X//d/4zzh0KC7Z\nn/BtbRHo2U9adXX815x9dvxnZz/Rra3xc3vPnvgkveY18OpXxycy2+KbPHnwv3fBgvhvHiZ4fiUb\nkJ2dMV19/ei8JxXS2hrhdfhwBEZ/f4RNtru1u3uwl+XQocGQ7OgY7IZ1j7f1tNMiCFpaBnsxsr0X\nHR3Rg5T746WqKlbn0O/XQubMiVDPfi9nv+sGBmK1L1kSlwkTIpCbm4/9kdbQED++zj8/at6zJ/6F\n9u0b/LFXVRU/9HbtimVYtgzOOy96j/r64n3o6ooQW7AglntgIN7Dw4djHmecEe8jxL/4zp3xLzt3\nboRxub9zJSjcR5p7fJIfeigCfOfOwf7WtjZYv36wOVNXFylSVzfYVJg+PVqsF1wQfbnLlhXeWDZO\nHD4cb182RCFCZvv2aK22tg4G8csvR7i1ZQ6OkW0xZVtU/f3Ryt2//+Rqqa2NcMu20rJdzAMDsarn\nzo3vxew2v7q6CLzFiyP82tqixgMHBld5ppuZ2tr4Xs22Evv7I7DPPz+WfTjuI7MtVJKl1HDXBtVS\n9PbC978PX/lKdKF0dh7b9zttWvxe27w5fu9NmADvfje8853wtrdFc2kcOXIkWpJmccn+UNm/P4J6\nYCAuHR2DLc/nn4+eoOefH3ydOXMiCHfvPn4ekyZFCGb7Pauqjt0WmQ3Cd797cPvozJmD3QTd3TH/\njo4I5oaGmN+MGfHakyfHahwapv390bLNfvGMJgW7nAiF+1DZDZZbt8Zl82b47nfjvsZG+O3fHhxS\ntmAB/MZvxO/ZkexkG2UHDsSIupqaCLmamvgJ/+KLEbQDA4PbHzs6IrT374+3aM+e4/tfi5k0KVq8\nF14IV18dYZ0daHLkCJx1VvRWnXnmYFd/pb4vs33fImOdwh0ilf72b+HhhyPQDx0afKyuDt74xmi1\nX3ppaj7ZnZ2x2C+/HD82Dh6Mbo///M/oZRo6ICVr4sQI+2wf8PTpg0OqzzkHLr44uv4nT47vSffo\nkshuEJsyZfCLYerU2Kg2fbpapSLlNr7DvbMTPvMZ+Lu/i66XN7wB3vve+B1/zjlxvWBBopKnpwd+\n9rMI6aefHuyfPnw4Hjcb3Pg3nAsvhI9+FN7ylvgey46uWLAgWtdz5iTq7RAZt8ZfuB84APffDz/8\nYWz0bGuDyy+HT30qfv8nRHt7DJnbvDla3Nkd+x57LIJ8woToLZo7N76npk2L57nHxrz58wdHQdTX\nR19zQ8Ox+y+JSHKNn3Dfswc+/WlYuzaarrNnRzfLH/1R9JuPMVu3wr33Rg9RdmTFSy8NDhHPHZNc\nUxNdIY2N8J73wKpV0T1SV1e5+kWkstIf7j098Od/DnfcER3FV18N114bO+eMgf5z9xjm19wcPyJ2\n7YK7747u/6qq2NiY3Z9p7twYMblqVfQYLV8eoylPP31MLIqIjCHpD/ePfxy+8AX4gz+Aj30sBhNX\nWF9fHCrlnnvgrruilZ5r+XL4+7+Hq66KkSOgMc4icmLSHe4/+lFsLH3f++DLXx712Xd1wQMPxGFb\nfv7zGMd94MCxezC+8Y3wgQ/EUL/siJLGxuODXMEuIiciveHe0hIjX5Yvh899blRn/fzz8V3y9a9H\nV0tVVXSfXHxxbLTMbry89NLoUhERKbd0hrs7/P7vRzP5v/5rxPd46eyM2fz0p3F5/PHoA3/Xu+C6\n6+Cii7RxU0RGVzrD/Z/+KYY5/uM/xnjAEXLwIHzpS/D5z8cempMmxdFhP/lJuOaaGGooIlIJ6Qv3\nrVvhxhvhkkvg/eU/QZR7tMzvugu+9rUYb/6bvwkf+lC00CtxzBERkaHSFe69vTHQe/LkSN4yboXs\n64sjEHzpS/H9MWFCHAL95pvjKLwiImNJusL9ttviZBP33Re7YJbJI4/Evk6PPx7dLl/5Clx2WYxs\nEREZi9IT7ps3R2f3e94TyVsG+/bFcVb++Z9jD9B///d4aQ1LFJGxLj3nSnnwwdgD9bbbTvml+vuj\ndX7OOTGc8UMfipMmXX65gl1EkiFdLfdp02IPoFOwcydccUXs/v+mN0Uf+6teVaYaRURGSUktdzNb\nZWbPmtl2M7tpmMfPMLMNZvakmT1oZovKX2oRW7bEAVdOoWm9fn2cnvSZZ+DOO2PvUgW7iCRR0XA3\ns2rgduASYDlwpZktHzLZZ4Bvuvv5wK3Ap8pdaFHZcD9Jn/hEDGlsbIzD5l51lbpgRCS5Smm5rwS2\nu3uTu/cA9wBrhkyzHPhJ5u8Hhnl8ZB08GIdVPMlwX7sW/uqv4mgFDz+cqMO6i4gMq5RwXwjsyrm9\nO3NfrieAd2f+fhcwzcyOGyhoZteb2SYz29Ta2noy9Q5vy5a4Xj70B0VxDz8MN9wA73hHbDydPLl8\nZYmIVEq5Rsv8GfAmM/sl8CZgD9A/dCJ3X+vuK9x9RUNDQ5lmzWC4n2DLfe/eGAHT2Ajf+paOiS4i\n6VHKaJk9QO4QlEWZ+37F3V8i03I3szrgMndvL1eRRW3ZEvv9n8Cx2vv74Xd+Jw4f8PDDOr2ciKRL\nKS33jcAyM1tiZrXAFcC63AnMbI6ZZV/rZuDr5S2ziM2b44DoJ9D0/vKX4X/+J07QdP75I1ibiEgF\nFA13d+8DbgDuB7YA97r7M2Z2q5mtzkz2ZuBZM9sGnAZ8coTqHd4JjpTZuxf+4i/gbW+LHVpFRNKm\npJ2Y3H09sH7Ifbfk/H0fcF95SytRVxfs2HFCKX3jjfG022/XcEcRSafkH35g27Y4Dm+JLfcHH4R/\n+zf4yEeiJ0dEJI2SH+4nMFKmtxf++I9ju+tHPzrCdYmIVFDyjy2zZUucpLSEZvh3vhOTf+c7Gs8u\nIumWjpb70qVxjrsC3OGzn43vgHe+c5RqExGpkHS03EvokvnZz+I8HnfcEQ19EZE0S3bM9fXBs8+W\nFO6f/WycOem97x2FukREKizZ4d7UFFtJi4T7c8/BunVxqrwpU0apNhGRCkp2uJc4UuYLX4gTWr//\n/aNQk4jIGJDscN++Pa4LjJRpb4d/+Rf4vd+DefNGqS4RkQpLdrg3NcHMmVBfn3eSH/849ka99tpR\nrEtEpMKSHe47dsQwyAI2bIC6Oli5cpRqEhEZA5Id7k1NRQ/zu2FDnOh6woRRqklEZAxIbrgPDMAL\nLxQM9127YqTMW986emWJiIwFyQ335mY4erRgt8xPMmd1vfjiUapJRGSMSG6479gR1wVa7j/5CcyZ\nA+edN0o1iYiMEckN96amuM7TcneP/va3vEWHGxCR8Se5sbdjR5xp44wzhn34uedgzx71t4vI+JTc\ncG9qgoUL48TYw9iwIa4V7iIyHiU33HfsKNjfvmEDNDbCmWeOYk0iImNEssM9T3/7wAA88EC02nWO\nVBEZj5IZ7kePRod6npb7U09BW5uGQIrI+JXMcH/xxRgOkyfcn3wyrlesGMWaRETGkGSGe5FhkFu2\nQE0NnHXWKNYkIjKGlBTuZrbKzJ41s+1mdtMwj59uZg+Y2S/N7Ekzu7T8peYosgPTli0R7DqejIiM\nV0XD3cyqgduBS4DlwJVmtnzIZB8D7nX3VwNXAP9U7kKP0dQUQyDnzx/24RJPqyoiklqltNxXAtvd\nvcnde4B7gDVDpnFgeubvGcBL5StxGDt2wOLFw+562tMT5/BQuIvIeFZKuC8EduXc3p25L9cngKvM\nbDewHviT4V7IzK43s01mtqm1tfUkys1oasrb3759O/T3K9xFZHwr1wbVK4F/dfdFwKXAnWZ23Gu7\n+1p3X+HuKxoaGk5+bgV2YCrxtKoiIqlWSrjvARpzbi/K3JfrWuBeAHd/GJgEzClHgcc5cCBOjFpg\npAzAueeOyNxFRBKhlHDfCCwzsyVmVktsMF03ZJqdwFsBzOwVRLifQr9LASWMlDn9dJg6dUTmLiKS\nCEXD3d37gBuA+4EtxKiYZ8zsVjNbnZnsw8AfmtkTwN3ANe7uI1Jxdox7gXBXl4yIjHc1pUzk7uuJ\nDaW5992S8/dm4KLylpZHtuU+TLfMwABs3RrnTBURGc9KCvcx5bLL4hjuM2Yc99DOndDVBcuHjsIX\nERlnkhfuS5cW3ZiqbhkRGe+SeWyZPBTuIiIhdeHe0ACzZ1e6EhGRykpduKvVLiKSonB3V7iLiGSl\nJtxbW+PsSwp3EZEUhbs2poqIDEpNuL/4Ylzn2XFVRGRcSU24790b13nO3yEiMq6kJtybm6GuLi4i\nIuNdqsJ93rxKVyEiMjakJtz37lWXjIhIVmrCvblZ4S4ikpWqcFe3jIhISEW4d3bCoUNquYuIZKUi\n3DUMUkTkWKkI9+bmuFa3jIhISFW4q+UuIhJSEe7qlhEROVYqwr25GWpqdJIOEZGs1IT7aadBVSqW\nRkTk1KUiDrV3qojIsUoKdzNbZWbPmtl2M7tpmMc/b2aPZy7bzKy9/KXmpx2YRESOVVNsAjOrBm4H\n3g7sBjaa2Tp335ydxt3/NGf6PwFePQK15tXcDCtXjuYcRUTGtlJa7iuB7e7e5O49wD3AmgLTXwnc\nXY7iStHXF6fYU7eMiMigUsJ9IbAr5/buzH3HMbMzgCXAT/I8fr2ZbTKzTa2trSda67BaWuLk2OqW\nEREZVO4NqlcA97l7/3APuvtad1/h7isaGhrKMkPtwCQicrxSwn0P0Jhze1HmvuFcwSh2yYB2YBIR\nGU4p4b4RWGZmS8yslgjwdUMnMrNzgXrg4fKWWJiOKyMicryi4e7ufcANwP3AFuBed3/GzG41s9U5\nk14B3OPuPjKlDk/hLiJyvKJDIQHcfT2wfsh9twy5/YnylVW6vXth1iyYOLEScxcRGZsSv4eqdmAS\nETleKsJdG1NFRI6lcBcRSaFEh7t79LmrW0ZE5FiJDvf2djh6VC13EZGhEh3u2jtVRGR4iQ737N6p\n6pYRETmWwl1EJIUSHe4dHXE9c2Zl6xARGWsSHe5dXXE9eXJl6xARGWsSHe7d3XE9aVJl6xARGWtS\nEe46royIyLESHe5dXdFqN6t0JSIiY0uiw727W10yIiLDSXS4Z1vuIiJyrESHe3e3RsqIiAwn8eGu\nlruIyPESHe7qlhERGV6iw13dMiIiw0t8uKvlLiJyvESHe1eXWu4iIsNJdLir5S4iMjyFu4hICpUU\n7ma2ysyeNbPtZnZTnml+x8w2m9kzZvat8pY5PHXLiIgMr6bYBGZWDdwOvB3YDWw0s3XuvjlnmmXA\nzcBF7n7AzOaOVMG51HIXERleKS33lcB2d29y9x7gHmDNkGn+ELjd3Q8AuHtLecscnsa5i4gMr5Rw\nXwjsyrm9O3NfrrOBs83sITN7xMxWDfdCZna9mW0ys02tra0nV3GGu8a5i4jkU64NqjXAMuDNwJXA\nP5vZcSe/c/e17r7C3Vc0NDSc0gx7euJaLXcRkeOVEu57gMac24sy9+XaDaxz91533wFsI8J+xOgU\neyIi+ZUS7huBZWa2xMxqgSuAdUOm+R7RasfM5hDdNE1lrPM4OsWeiEh+RcPd3fuAG4D7gS3Ave7+\njJndamarM5PdD+w3s83AA8CN7r5/pIoGhbuISCFFh0ICuPt6YP2Q+27J+duBD2Uuo0LdMiIi+SV2\nD1W13EVE8lO4i4ikUGLDXd0yIiL5JTbc1XIXEckvseGebbkr3EVEjpfYcM+23NUtIyJyvMSHu1ru\nIiLHS2y4a4OqiEh+iQ13tdxFRPJTuIuIpFBiw72rC6qrYcKESlciIjL2JDbcdYo9EZH8FO4iIimU\n2HDv6tJIGRGRfBIb7mq5i4jkl9hwV8tdRCS/xIa7Wu4iIvkp3EVEUiix4a5uGRGR/BIb7mq5i4jk\np3AXEUmhxIa7umVERPJLbLir5S4ikl9J4W5mq8zsWTPbbmY3DfP4NWbWamaPZy7Xlb/UYyncRUTy\nqyk2gZlVA7cDbwd2AxvNbJ27bx4y6bfd/YYRqHFY6pYREcmvlJb7SmC7uze5ew9wD7BmZMsqrL8f\nenvVchcRyaeUcF8I7Mq5vTtz31CXmdmTZnafmTUO90Jmdr2ZbTKzTa2trSdRbtDJsUVECivXBtXv\nA4vd/XzgR8A3hpvI3de6+wp3X9HQ0HDSM9NZmERECisl3PcAuS3xRZn7fsXd97v70czNrwKvKU95\nw1O4i4gUVkq4bwSWmdkSM6sFrgDW5U5gZvNzbq4GtpSvxON1dcW1umVERIZXdLSMu/eZ2Q3A/UA1\n8HV3f8bMbgU2ufs64ANmthroA9qAa0awZrXcRUSKKBruAO6+Hlg/5L5bcv6+Gbi5vKXlp3AXESks\nkXuoqltGRKSwRIa7Wu4iIoUp3EVEUiiR4a5uGRGRwhIZ7mq5i4gUlshwV8tdRKSwRIa7Wu4iIoUp\n3EVEUiiR4Z7tllG4i4gML5Hh3t0NtbVQlcjqRURGXiLjUafYExEpLJHhrlPsiYgUlshwV8tdRKSw\nxIa7Wu4iIvklMty7utRyFxEpJJHhrm4ZEZHCEhnu2qAqIlJYIsNdLXcRkcIU7iIiKZTIcFe3jIhI\nYYkMd7XcRUQKU7iLiKRQIsNd3TIiIoWVFO5mtsrMnjWz7WZ2U4HpLjMzN7MV5SvxWO5quYuIFFM0\n3M2sGrgduARYDlxpZsuHmW4a8EHg0XIXmauvDwYG1HIXESmklJb7SmC7uze5ew9wD7BmmOn+Gvg0\n0F3G+o6jE3WIiBRXSrgvBHbl3N6due9XzOxCoNHdf1jG2oalU+yJiBR3yhtUzawK+Bzw4RKmvd7M\nNpnZptbW1pOaX7blrm4ZEZH8Sgn3PUBjzu1FmfuypgGvAh40sxeA1wLrhtuo6u5r3X2Fu69oaGg4\nqYLVchcRKa6UcN8ILDOzJWZWC1wBrMs+6O4H3X2Ouy9298XAI8Bqd980EgUr3EVEiisa7u7eB9wA\n3A9sAe5192fM7FYzWz3SBQ6lbhkRkeJqSpnI3dcD64fcd0uead986mXlp5a7iEhxidtDNRvuarmL\niOSXuHDXOHcRkeISF+7qlhGEiQjfAAAEWklEQVQRKS6x4a5uGRGR/BIX7uqWEREpLnHhrm4ZEZHi\nEhfuZ54Jl12mbhkRkUJKGuc+lqxZExcREckvcS13EREpTuEuIpJCCncRkRRSuIuIpJDCXUQkhRTu\nIiIppHAXEUkhhbuISAqZu1dmxmatwIsn+fQ5wL4ylpMU43G5x+Myw/hc7vG4zHDiy32Guxc9CXXF\nwv1UmNkmdz/uBNxpNx6XezwuM4zP5R6Pywwjt9zqlhERSSGFu4hICiU13NdWuoAKGY/LPR6XGcbn\nco/HZYYRWu5E9rmLiEhhSW25i4hIAQp3EZEUSly4m9kqM3vWzLab2U2VrmckmFmjmT1gZpvN7Bkz\n+2Dm/llm9iMzey5zXV/pWsvNzKrN7Jdm9oPM7SVm9mhmfX/bzGorXWO5mdlMM7vPzLaa2RYze904\nWdd/mvn/ftrM7jazSWlb32b2dTNrMbOnc+4bdt1a+IfMsj9pZheeyrwTFe5mVg3cDlwCLAeuNLPl\nla1qRPQBH3b35cBrgfdnlvMmYIO7LwM2ZG6nzQeBLTm3Pw183t3PAg4A11akqpH1ReA/3f1c4NeI\n5U/1ujazhcAHgBXu/iqgGriC9K3vfwVWDbkv37q9BFiWuVwP3HEqM05UuAMrge3u3uTuPcA9QOpO\nuufuze7+i8zfh4gP+0JiWb+RmewbwDsrU+HIMLNFwG8CX83cNuBi4L7MJGlc5hnAG4GvAbh7j7u3\nk/J1nVEDTDazGmAK0EzK1re7/zfQNuTufOt2DfBND48AM81s/snOO2nhvhDYlXN7d+a+1DKzxcCr\ngUeB09y9OfPQXuC0CpU1Ur4AfAQYyNyeDbS7e1/mdhrX9xKgFfiXTHfUV81sKilf1+6+B/gMsJMI\n9YPAY6R/fUP+dVvWfEtauI8rZlYHfAf4v+7ekfuYxxjW1IxjNbPfAlrc/bFK1zLKaoALgTvc/dVA\nJ0O6YNK2rgEy/cxriC+3BcBUju++SL2RXLdJC/c9QGPO7UWZ+1LHzCYQwX6Xu383c/fL2Z9pmeuW\nStU3Ai4CVpvZC0R328VEX/TMzM92SOf63g3sdvdHM7fvI8I+zesa4G3ADndvdfde4LvE/0Da1zfk\nX7dlzbekhftGYFlmi3otsQFmXYVrKrtMX/PXgC3u/rmch9YBV2f+vhr4j9GubaS4+83uvsjdFxPr\n9Sfu/nvAA8DlmclStcwA7r4X2GVm52TueiuwmRSv64ydwGvNbErm/z273Kle3xn51u064L2ZUTOv\nBQ7mdN+cOHdP1AW4FNgGPA/8RaXrGaFlfD3xU+1J4PHM5VKiD3oD8BzwY2BWpWsdoeV/M/CDzN9L\ngZ8D24F/ByZWur4RWN4LgE2Z9f09oH48rGvgr4CtwNPAncDEtK1v4G5im0Iv8Svt2nzrFjBiNODz\nwFPESKKTnrcOPyAikkJJ65YREZESKNxFRFJI4S4ikkIKdxGRFFK4i4ikkMJdRCSFFO4iIin0/wFc\ni4NhkijE7wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPZSXVf9ao7E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}