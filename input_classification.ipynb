{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "input_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrtS3fRhb5x6",
        "colab_type": "text"
      },
      "source": [
        "# 1. Importation des librairies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MS3XuLGyb5x_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import Image, HTML, display\n",
        "from matplotlib import pyplot as plt\n",
        "from keras.preprocessing import image\n",
        "from keras.models import Model, load_model\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2 \n",
        "import os\n",
        "import csv\n",
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "from keras.backend.tensorflow_backend import set_session\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.layers import Dense, GlobalAveragePooling2D, Activation, Flatten\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras.applications.xception import Xception, preprocess_input, decode_predictions #299*299\n",
        "from keras.applications.vgg16 import VGG16, preprocess_input\n",
        "from keras.applications.vgg19 import VGG19, preprocess_input\n",
        "from keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions #224*224\n",
        "from keras.applications.inception_v3 import InceptionV3, preprocess_input,decode_predictions# input shape= 299x299\n",
        "from keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input,decode_predictions# input shape= 299x299\n",
        "from keras.applications.mobilenet import MobileNet, preprocess_input\n",
        "from keras.applications.densenet import DenseNet121, preprocess_input, decode_predictions# input shape= 224x224 \n",
        "from keras.applications.densenet import DenseNet169, preprocess_input\n",
        "from keras.applications.densenet import DenseNet201, preprocess_input\n",
        "from keras.applications.nasnet import NASNetLarge, preprocess_input\n",
        "from keras.applications.nasnet import NASNetMobile, preprocess_input\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "import math\n",
        "import argparse\n",
        "import matplotlib\n",
        "import imghdr\n",
        "import pickle as pkl\n",
        "import datetime\n",
        "from cycler import cycler\n",
        "from PIL import Image, ImageEnhance"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPDeDv3lcBN-",
        "colab_type": "text"
      },
      "source": [
        "# 2. Téléchargement de la base de données (commençons par la petite : Small)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFOL9AjHcFZC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! wget https://github.com/belarbi2733/keras_yolov3/releases/download/1/defi1certif-datasets-fire_small.tar"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0EQ6z1TcTp-",
        "colab_type": "text"
      },
      "source": [
        "# 3. Décompression du dossier vers un le nouveau dossier \"bases/small\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjBhTzP6UrJY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bases_path_after=\"bases\"\n",
        "# Création du dossier pour sauvegrader le model\n",
        "if os.path.exists(bases_path_after) == False:\n",
        "    os.makedirs(bases_path_after)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6_GtgxrUu1T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar xf defi1certif-datasets-fire_small.tar -C 'bases' --one-top-level && mv bases/defi1certif-datasets-fire_small bases/small"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_aVcLobc7o6",
        "colab_type": "text"
      },
      "source": [
        "# 4. Création du fichier \"classes.txt\" (labels des données d'entrainement): "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVinEd9MU2Mb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!for d in bases/small/*;do [[ -d \"$d\" ]] && echo \"${d##bases/small/}\" >> classes.txt; done"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCDoxF6Xb5yN",
        "colab_type": "text"
      },
      "source": [
        "# 5. Génération des données à partir de chemins"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzwI7D2Tb5yX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_from_paths_and_labels(input_paths, labels, batch_size, input_size=(299,299)):\n",
        "\n",
        "    num_samples = len(input_paths)\n",
        "    while 1:\n",
        "        perm = np.random.permutation(num_samples)\n",
        "        input_paths = input_paths[perm]\n",
        "        labels = labels[perm]\n",
        "        for i in range(0, num_samples, batch_size):\n",
        "            inputs = list(map(\n",
        "                lambda x: image.load_img(x, target_size=input_size),\n",
        "                input_paths[i:i+batch_size]\n",
        "            ))\n",
        "            inputs = np.array(list(map(\n",
        "                lambda x: image.img_to_array(x),\n",
        "                inputs\n",
        "            )))\n",
        "            inputs = preprocess_input(inputs)\n",
        "            yield (inputs, labels[i:i+batch_size])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAwK6yYjb5yj",
        "colab_type": "text"
      },
      "source": [
        "# 6. Définition des paramètres (l'interface à droite vous permet de changer les paramètres aussi)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yaeguet_b5yn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nb_classes = 3\n",
        "nbr_batch_size=8 #@param [1,2,4,8,16,32,64,128] {type:\"raw\"}\n",
        "dataset_path = \"bases\"\n",
        "dataset_name='small' #@param [\"small\",\"medium\",\"big\",\"personal\"]\n",
        "\n",
        "dataset_path = os.path.join('bases/', dataset_name)\n",
        "classes_path = \"classes.txt\"\n",
        "csv_path = 'result.csv'\n",
        "epochs = 10 #@param {type:\"slider\", min:5, max:100, step:5}\n",
        "\n",
        "seed = 1\n",
        "classifier = \"VGG16\" #@param [\"SqueezeNet\",\"Xception\",\"VGG16\",\"VGG19\",\"ResNet50\",\"InceptionV3\",\"InceptionResNetV2\",\"MobileNet\",\"DenseNet121\",\"DenseNet169\",\"DenseNet201\",\"NASNetLarge\",\"NASNetMobile\"] {type:\"string\"}\n",
        "result_path = 'results/'+classifier\n",
        "log={\n",
        "    'epochs':epochs,\n",
        "    'batch_size':nbr_batch_size,\n",
        "    'val_loss':-1,\n",
        "    'val_acc':-1,\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SBzh646b5yz",
        "colab_type": "text"
      },
      "source": [
        "# 7. Récupérer les images ainsi que leurs classes  (étape pouvant prendre quelques minutes)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZ55HVhkb5y3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Récupurer les noms des classes\n",
        "with open(classes_path, 'r') as f:\n",
        "    classes = f.readlines()\n",
        "    classes = list(map(lambda x: x.strip(), classes))\n",
        "num_classes = len(classes)\n",
        "\n",
        "# Récupurer les images et les classes\n",
        "input_paths, labels = [], []\n",
        "for class_name in os.listdir(dataset_path):\n",
        "    class_path = os.path.join(dataset_path, class_name)\n",
        "    class_id = classes.index(class_name)\n",
        "    for path in os.listdir(class_path):\n",
        "        path = os.path.join(class_path, path)\n",
        "        if imghdr.what(path) == None:\n",
        "            # this is not an image file\n",
        "            continue\n",
        "        input_paths.append(path)\n",
        "        labels.append(class_id)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTyWV0pQb5zD",
        "colab_type": "text"
      },
      "source": [
        "# 8. Préparer les données"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKp1l4jAb5zG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Question 1: Convertir les lebels vers le format one-hot-vector\n",
        "???????????????????????????????????????\n",
        "\n",
        "# Question 2: Convertir \"convert \"input paths\" vers le format numpy\n",
        "???????????????????????????????????????\n",
        "\n",
        "# shuffle dataset (permuter les données)\n",
        "perm = np.random.permutation(len(input_paths))\n",
        "labels = labels[perm]\n",
        "input_paths = input_paths[perm]\n",
        "\n",
        "# Question3 : Diviser les données en deux parties : entrainement et validation\n",
        "???????????????????????????????????????\n",
        "\n",
        "train_labels, val_labels = labels[:border], labels[border:]\n",
        "train_input_paths, val_input_paths = input_paths[:border], input_paths[border:]\n",
        "print(\"Training on %d images and labels\" % (len(train_input_paths)))\n",
        "print(\"Validation on %d images and labels\" % (len(val_input_paths)))\n",
        "\n",
        "# Création du dossier pour sauvegrader le model\n",
        "if os.path.exists(result_path) == False:\n",
        "    os.makedirs(result_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wi8oBrIJWa5s",
        "colab_type": "text"
      },
      "source": [
        "# 9. Téléchargement d'un modèle pré-entraîné et Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WCBo9Oyb5zc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model = VGG16(include_top=False, weights='imagenet', input_shape=(224,224,3))  # La pouvez tester différentes architectures\n",
        "\n",
        "# create a custom top classifier\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "predictions = Dense(num_classes, activation='softmax')(x)\n",
        "model = Model(inputs=base_model.inputs, outputs=predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6CWnXEPb5zX",
        "colab_type": "text"
      },
      "source": [
        "# 9. Entraînement du modèle "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPGAZ2Vab5zo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# ====================================================\n",
        "# Train the whole model\n",
        "# ====================================================\n",
        "# set all the layers to be trainable\n",
        "for layer in model.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "# Question 4: compiler le modèle \"model\"\n",
        "????????????????????????????????????????????????????????\n",
        "\n",
        "# Création du dossier pour sauvegrader le model\n",
        "if os.path.exists(result_path) == False:\n",
        "    os.makedirs(result_path)\n",
        "\n",
        "# Question 5 : Compléter l'appel a fonction fit_generator pour l'entrainement \n",
        "history=model.fit_generator(\n",
        "    generator=generate_from_paths_and_labels(\n",
        "        input_paths=train_input_paths,\n",
        "        labels=train_labels,\n",
        "        batch_size=nbr_batch_size,\n",
        "        input_size=(???,???,3)\n",
        "        \n",
        "    ),\n",
        "    steps_per_epoch=math.ceil(len(train_input_paths) / nbr_batch_size),\n",
        "    epochs=epochs,\n",
        "    validation_data=generate_from_paths_and_labels(\n",
        "        input_paths=???,\n",
        "        labels=???,\n",
        "        batch_size=nbr_batch_size,\n",
        "        input_size=(???,???,3)\n",
        "    ),\n",
        "    validation_steps=math.ceil(len(val_input_paths) / nbr_batch_size),\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Question 6 : Sauvegarder le modèle final\n",
        "??????"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIuhZQ-fb5z1",
        "colab_type": "text"
      },
      "source": [
        "# 10. Tester le modèle (étape pouvant prendre quelques minutes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rtsaeGSckRd",
        "colab_type": "text"
      },
      "source": [
        "## Charger une image de test depuis internet\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odSTtpMpcjLz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget -O fire.jpg https://media.wired.com/photos/5be5baad89450468242a14ba/master/pass/CampFire-1059476842.jpg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juBbFpYnyB-H",
        "colab_type": "text"
      },
      "source": [
        "## Tester modèle avec l'image chargée \"fire.jpg\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QO_vM07lb5z5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "model_path=\"results/VGG16/classification_final.h5\"   # Ici, vous devez indiquer votre modèle\n",
        "classes_path = \"classes.txt\"\n",
        "image_path=\"fire.jpg\"                # Votre image de test   \n",
        "top_n=3\n",
        "model = load_model(model_path)\n",
        "\n",
        "# load class names\n",
        "classes = []\n",
        "with open(classes_path, 'r') as f:\n",
        "    classes = list(map(lambda x: x.strip(), f.readlines()))\n",
        "\n",
        "img = image.load_img(image_path, target_size=(224,224))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = preprocess_input(x)\n",
        "\n",
        "# predict\n",
        "pred = model.predict(x)[0]\n",
        "result = [(classes[i], float(pred[i]) * 100.0) for i in range(len(pred))]\n",
        "result.sort(reverse=True, key=lambda x: x[1])\n",
        "\n",
        "img = cv2.imread(image_path)\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "font = cv2.FONT_HERSHEY_COMPLEX \n",
        "\n",
        "for i in range(top_n):\n",
        "    (class_name, prob) = result[i]\n",
        "    textsize = cv2.getTextSize(class_name, font, 1, 2)[0]\n",
        "    textX = (img.shape[1] - textsize[0]) / 2\n",
        "    textY = (img.shape[0] + textsize[1]) / 2\n",
        "    if (i == 0) :\n",
        "        cv2.putText(img, class_name, (int(textX)-100, int(textY)), font, 5, (255,255,255), 6, cv2.LINE_AA)\n",
        "    print(\"Top %d ====================\" % (i + 1))\n",
        "    print(\"Class name: %s\" % (class_name))\n",
        "    print(\"Probability: %.2f%%\" % (prob))\n",
        "plt.imshow(img)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
