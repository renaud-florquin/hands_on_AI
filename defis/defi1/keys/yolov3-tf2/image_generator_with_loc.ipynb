{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import PIL\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import argparse\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "\n",
    "def int64_list_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
    "\n",
    "\n",
    "def bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "\n",
    "def bytes_list_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=value))\n",
    "\n",
    "\n",
    "def float_list_feature(value):\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
    "\n",
    "\n",
    "def get_output_filename(output_dir, name, idx):\n",
    "    return os.path.join(output_dir, '{}_{:03}.tfrecord'.format(name, idx))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_limits(projection, epsilon):\n",
    "    \"\"\" This function finds the interval where the histogram is at (eps:1-eps)\n",
    "    \"\"\"\n",
    "    integration = 0\n",
    "    start = 0\n",
    "    for i in range(len(projection)):\n",
    "        integration += projection[i]\n",
    "        if not start and integration > epsilon:\n",
    "            start = i\n",
    "        if integration > 1 - epsilon:\n",
    "            end = i\n",
    "            break\n",
    "    return (start, end)\n",
    "\n",
    "def find_bounding_box(alpha_channel):\n",
    "    \"\"\"Find the bounding box of an image, based on its alpha channel\n",
    "    The idea is to project the alpha value on the X and Y axis to get their histogram,\n",
    "    then to define the box where 99,9% of the image opacity is.\n",
    "    :param alpha_channel: Image alpha channel\n",
    "    :returns: (x, y, width, height) of the bounding box\n",
    "    \"\"\"\n",
    "    prj_h = np.sum(alpha_channel, axis=0)\n",
    "    prj_v = np.sum(alpha_channel, axis=1)\n",
    "    prj_tot = np.sum(prj_h)\n",
    "\n",
    "    # Find bounding box limits along X and Y\n",
    "    (sx, ex) = find_limits(prj_h / prj_tot, 0.001)\n",
    "    (sy, ey) = find_limits(prj_v / prj_tot, 0.001)\n",
    "\n",
    "    return (sx, sy, ex - sx, ey - sy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_object(path, size, rotation=0,flip=False):\n",
    "    \"\"\" Load a object image, with alpha channel included, and resize it, rotate it,\n",
    "    and ajust its bounding box tightly\n",
    "\n",
    "    :param path: Path to the image\n",
    "    :param size: Highest dimension (width or height) of the final image [px]\n",
    "    :param rotation: Rotation to apply to the image [deg]\n",
    "    :param flip: True to flip the image along the horizontal axis\n",
    "    :returns: object image\"\"\"\n",
    "\n",
    "    # Open image\n",
    "    obj = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
    "    if obj is None:\n",
    "        return \"bad_image\"\n",
    "    obj = cv2.cvtColor(obj, cv2.COLOR_BGRA2RGBA)\n",
    "    if flip:\n",
    "        obj = cv2.flip(obj, 0)\n",
    "    (height, width) = obj.shape[:2]\n",
    "\n",
    "    # Increase canvas size to ensure to make any rotation without losing pixels\n",
    "    dim = int(max(height, width) * 2 ** 0.5)\n",
    "    new_canvas = np.zeros((dim, dim, 4), dtype=np.uint8)\n",
    "\n",
    "    offx = (dim - width) // 2\n",
    "    offy = (dim - height) // 2\n",
    "    new_canvas[offy:offy + height, offx:offx + width, :] = obj\n",
    "    obj = new_canvas\n",
    "\n",
    "    # Apply the rotation\n",
    "    rot_mtx = cv2.getRotationMatrix2D((dim // 2, dim // 2), rotation, 1)\n",
    "    obj = cv2.warpAffine(obj, rot_mtx, (dim, dim))\n",
    "\n",
    "    # Find bounding box and remove what is outside\n",
    "    alpha_channel = obj[:, :, 3]\n",
    "    (x, y, w, h) = find_bounding_box(alpha_channel)\n",
    "    obj = obj[y:y + h, x:x + w, :]\n",
    "    (height, width) = (h, w)\n",
    "\n",
    "    # Resize image so that its highest dimension is 'size'\n",
    "    f_width = width / size\n",
    "    f_height = height / size\n",
    "    f = max(f_width, f_height)\n",
    "    obj = cv2.resize(obj, None, fx=1 / f, fy=1 / f,\n",
    "                     interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    return obj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_background(path, target_width, target_height):\n",
    "    \"\"\"Load a background image, while ensuring its size fits the requested one.\n",
    "    If needed, image is cropped to preserve the aspect ratio.\n",
    "    :param path: Path to the image\n",
    "    :param target_width: Desired width\n",
    "    :param target_height: Desired height\n",
    "    :returns: background image\"\"\"\n",
    "\n",
    "    background = cv2.imread(path)\n",
    "    if background is None:\n",
    "        return \"bad_image\"\n",
    "    background = cv2.cvtColor(background, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Find scaling factor, so that the image is just bigger than requested (one dimension fit, the other is bigger)\n",
    "    (height, width) = background.shape[:2]\n",
    "    f_width = width / target_width\n",
    "    f_height = height / target_height\n",
    "    f = min(f_width, f_height)\n",
    "\n",
    "    # Resize\n",
    "    background = cv2.resize(background, None, fx=1 / f, fy=1 / f,\n",
    "                            interpolation=cv2.INTER_AREA)\n",
    "    (height, width) = background.shape[:2]\n",
    "\n",
    "    # Then crop what is outside the requested size, with a random offset\n",
    "    (height, width) = background.shape[:2]\n",
    "    if height > target_height:\n",
    "        offset = int(np.random.uniform(0, height - target_height))\n",
    "\n",
    "        # offset = (height-target_height)//2\n",
    "        background = background[offset:offset + target_height, :, :]\n",
    "    elif width > target_width:\n",
    "\n",
    "        offset = int(np.random.uniform(0, width - target_width))\n",
    "\n",
    "        # offset = (width-target_width)//2\n",
    "        background = background[:, offset:offset + target_width, :]\n",
    "\n",
    "    return background\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_obj_to_background(background, obj, x, y, blurr=0):\n",
    "    \"\"\" Patch a background image by the addition of a foreground image.\n",
    "    The two images are combined by mixing them according to the obj alpha channel.\n",
    "\n",
    "    :param background: Background image\n",
    "    :param obj: object image to add to the background\n",
    "    :param x: x position in the background where to add the object.\n",
    "    :param y: y position in the background where to add the object.\n",
    "    :returns: background image\"\"\"\n",
    "\n",
    "    obj_alpha = obj[:, :, 3]\n",
    "    obj_rgb = obj[:, :, :3]\n",
    "    (height, width) = obj.shape[:2]\n",
    "\n",
    "    # For each alpha value at x, y position, create a triplet of this same value\n",
    "    alpha_factor = 0.9 * obj_alpha[:, :, np.newaxis].astype(np.float32) / 255.0\n",
    "    alpha_factor = np.concatenate((alpha_factor, alpha_factor, alpha_factor), axis=2)\n",
    "\n",
    "    # Compute the patch to apply to the image (mix of background and foreground)\n",
    "    obj_rgb = obj_rgb.astype(np.float32) * alpha_factor\n",
    "    patch = background.astype(np.float32)[y:y + height, x:x + width] * (1 - alpha_factor)\n",
    "    patch += obj_rgb\n",
    "\n",
    "    # patch the image\n",
    "    background[y:y + height, x:x + width] = patch.astype(np.uint8)\n",
    "\n",
    "    # A bit of blurring\n",
    "    kernel_size = int(round(3 * blurr)) * 2 + 1\n",
    "    blurred = cv2.GaussianBlur(background, (kernel_size, kernel_size), 0)\n",
    "\n",
    "    return blurred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_background(path_background):\n",
    "    back_paths = []\n",
    "    for path in os.listdir(path_background):\n",
    "        img_path = os.path.join(path_background, path)\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is not None:\n",
    "            back_paths.append(img_path)\n",
    "    return back_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_obj_with_class(path_object):\n",
    "    obj_paths = []\n",
    "    for class_obj in os.listdir(path_object):\n",
    "        class_obj_path = os.path.join(path_object, class_obj)\n",
    "        if os.path.isdir(class_obj_path):\n",
    "            for path in os.listdir(class_obj_path):\n",
    "                img_path = os.path.join(class_obj_path, path)\n",
    "                img = cv2.imread(img_path)\n",
    "                if img is not None:\n",
    "                    obj_paths.append((img_path, class_obj))\n",
    "    return obj_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_tfrecord(img_filename, data, tfrecord_writer):\n",
    "    with tf.io.gfile.GFile(img_filename, 'rb') as fid:\n",
    "        encoded_jpg = fid.read()\n",
    "    image = PIL.Image.open(img_filename)\n",
    "    if image.format != 'JPEG':\n",
    "        raise ValueError('Image format not JPEG')\n",
    "    sha256 = hashlib.sha256(encoded_jpg).hexdigest()\n",
    "\n",
    "    width, height = image.size\n",
    "\n",
    "    xmin, ymin, xmax, ymax, classes, classes_text, truncated, poses, difficult_obj = data\n",
    "    \n",
    "    example = tf.train.Example(features=tf.train.Features(feature={\n",
    "            'image/height': int64_feature(height),\n",
    "            'image/width': int64_feature(width),\n",
    "            'image/filename': bytes_feature(img_filename.encode('utf8')),\n",
    "            'image/source_id': bytes_feature(img_filename.encode('utf8')),\n",
    "            'image/key/sha256': bytes_feature(sha256.encode('utf8')),\n",
    "            'image/encoded': bytes_feature(encoded_jpg),\n",
    "            'image/format': bytes_feature('jpeg'.encode('utf8')),\n",
    "            'image/object/bbox/xmin': float_list_feature(xmin),\n",
    "            'image/object/bbox/xmax': float_list_feature(xmax),\n",
    "            'image/object/bbox/ymin': float_list_feature(ymin),\n",
    "            'image/object/bbox/ymax': float_list_feature(ymax),\n",
    "            'image/object/class/text': bytes_list_feature(classes_text),\n",
    "            'image/object/class/label': int64_list_feature(classes),\n",
    "            'image/object/bbox/difficult': int64_list_feature(difficult_obj),\n",
    "            'image/object/bbox/truncated': int64_list_feature(truncated),\n",
    "            'image/object/view': bytes_list_feature(poses),\n",
    "        }))\n",
    "    tfrecord_writer.write(example.SerializeToString())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(back_paths, obj_paths, tfrecord_writer, class_dict, output_path='result', nbr_images=10, max_nbr_objs=5, size_range=(60, 250), back_size=800):\n",
    "    for img_idx in range(nbr_images):\n",
    "        back_path = np.random.choice(back_paths)\n",
    "        nbr_objs = np.random.choice(range(0, max_nbr_objs)) + 1\n",
    "        obj_sizes = [np.random.uniform(*size_range) for _ in range(nbr_objs)]\n",
    "        obj_sizes.sort(reverse=False)\n",
    "\n",
    "        # Load backgroud image\n",
    "        b = load_background(back_path, back_size, back_size)\n",
    "\n",
    "        xmin = []\n",
    "        ymin = []\n",
    "        xmax = []\n",
    "        ymax = []\n",
    "        classes = []\n",
    "        classes_text = []\n",
    "        truncated = []\n",
    "        poses = []\n",
    "        difficult_obj = []\n",
    "        \n",
    "        for obj_index in range(nbr_objs):\n",
    "            obj_size = obj_sizes[obj_index]\n",
    "            choice_index = np.random.choice(range(len(obj_paths)))\n",
    "            obj_path, obj_class = obj_paths[choice_index]\n",
    "            x = int(np.random.uniform(back_size - obj_size - 1))\n",
    "            y = int(np.random.uniform(back_size - obj_size - 1))\n",
    "            angle = int(np.random.uniform(0, 360))\n",
    "            flip = np.random.choice((True, False))\n",
    "            blurr = np.random.uniform()\n",
    "\n",
    "            # Combine background and foreground\n",
    "            obj = load_object(obj_path, obj_size, angle, flip)\n",
    "            b = add_obj_to_background(b, obj, x, y, blurr)\n",
    "            (height, width) = obj.shape[:2]\n",
    "            \n",
    "            xmin.append(float(x) / back_size)\n",
    "            ymin.append(float(y) / back_size)\n",
    "            xmax.append(float(x + width) / back_size)\n",
    "            ymax.append(float(y + height) / back_size)\n",
    "            classes_text.append(obj_class.encode('utf8'))\n",
    "            classes.append(class_dict[obj_class])\n",
    "            truncated.append(int(0))\n",
    "            poses.append(''.encode('utf8'))\n",
    "            difficult_obj.append(int(0))  \n",
    "\n",
    "        # Save image\n",
    "        img_filename = 'gen_{:04d}.jpg'.format(img_idx)\n",
    "        img_filename = os.path.join(output_path, img_filename)\n",
    "        img = tf.keras.preprocessing.image.array_to_img(b)\n",
    "        img.save(img_filename)\n",
    "\n",
    "        data = (xmin, ymin, xmax, ymax, classes, classes_text, truncated, poses, difficult_obj)\n",
    "        add_to_tfrecord(img_filename, data, tfrecord_writer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "back_paths = retrieve_background('background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_paths = retrieve_obj_with_class('objects_with_class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_classes(class_filename):\n",
    "    with open('data/keys.names') as f:\n",
    "        lines = f.readlines()\n",
    "    return {l.strip():i for i, l in enumerate(lines)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dict = read_classes('data/keys.names')\n",
    "tf_filename = get_output_filename('result', 'keys', 1)\n",
    "with tf.io.TFRecordWriter(tf_filename) as tfrecord_writer:\n",
    "    generate_images(back_paths, obj_paths, tfrecord_writer, class_dict, 'result', nbr_images=20, max_nbr_objs=5, size_range=(60, 250), back_size=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    parser = argparse.ArgumentParser(argument_default=argparse.SUPPRESS)\n",
    "    parser.add_argument('--keys', type=str, required=True,\n",
    "                        help='path to keys path')\n",
    "\n",
    "    parser.add_argument('--background', type=str, required=True,\n",
    "                        help='path to background path')\n",
    "\n",
    "    parser.add_argument('--output', type=str,\n",
    "                        default='./keys_and_background',\n",
    "                        help='path to output, default keys_and_background '\n",
    "                        )\n",
    "    FLAGS = parser.parse_args()\n",
    "\n",
    "    NUM_IMAGES = 5000\n",
    "    KEY_SIZE_RANGE = (60, 250)\n",
    "    BACK_SIZE = 800\n",
    "\n",
    "    PATH_KEYS = FLAGS.keys\n",
    "    PATH_BACKGROUND = FLAGS.background\n",
    "    PATH_OUTPUT = FLAGS.output\n",
    "    os.mkdir(PATH_OUTPUT)\n",
    "\n",
    "\n",
    "    # Load paths to key\n",
    "\n",
    "    key_paths = []\n",
    "    for path in os.listdir(PATH_KEYS):\n",
    "        key_paths.append(os.path.join(PATH_KEYS, path))\n",
    "\n",
    "    # Load paths to backgrounds\n",
    "\n",
    "    back_paths = []\n",
    "    for path in os.listdir(PATH_BACKGROUND):\n",
    "        back_paths.append(os.path.join(PATH_BACKGROUND, path))\n",
    "\n",
    "    csv_lines = []\n",
    "    num_images = NUM_IMAGES\n",
    "    while num_images > 0:\n",
    "\n",
    "        # Choose configuration at random\n",
    "\n",
    "        back_path = np.random.choice(back_paths)\n",
    "        key_path = np.random.choice(key_paths)\n",
    "        key_size = np.random.uniform(*KEY_SIZE_RANGE)\n",
    "        x = int(np.random.uniform(BACK_SIZE - key_size - 1))\n",
    "        y = int(np.random.uniform(BACK_SIZE - key_size - 1))\n",
    "        angle = int(np.random.uniform(0, 360))\n",
    "        flip = np.random.choice((True, False))\n",
    "        flip_bckd = np.random.choice((True, False))\n",
    "        blurr = np.random.uniform()\n",
    "\n",
    "        # Combine background and foreground\n",
    "\n",
    "        print (back_path)\n",
    "        b = load_background(back_path, BACK_SIZE, BACK_SIZE, flip_bckd)\n",
    "        k = load_key(key_path, key_size, angle, flip)\n",
    "        if b == \"bad_image\":\n",
    "            print(b)\n",
    "            continue\n",
    "        elif k == \"bad_image\":\n",
    "            print(k)\n",
    "            continue\n",
    "        final = addkey_to_background(b, k, x, y, blurr)\n",
    "\n",
    "        # Save image\n",
    "\n",
    "        img_filename = 'gen_{:04d}.jpg'.format(num_images)\n",
    "        img = image.array_to_img(final)\n",
    "        img.save(os.path.join(PATH_OUTPUT, img_filename))\n",
    "\n",
    "        # Keep track of image bounding box\n",
    "\n",
    "        (height, width) = k.shape[:2]\n",
    "        csv_lines.append('{},{},{},{},{},0,key\\n'.format(img_filename, x,\n",
    "                         y, x + width, y + height))\n",
    "\n",
    "        num_images -= 1\n",
    "        if num_images % 100 == 0:\n",
    "            print (num_images, ' left')\n",
    "\n",
    "    with open(os.path.join(PATH_OUTPUT, 'annotations.csv'), 'w') as f:\n",
    "        f.write('filename,xmin,ymin,xmax,ymax,class_id,class_name\\n')\n",
    "        for l in csv_lines:\n",
    "            f.write(l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Convert a set of images and a CSV annotation file to TFRecord for object_detection.\n",
    "\n",
    "Example usage:\n",
    "    python convert_csv_to_tfrecord.py \\\n",
    "        --img_dir=keys_and_background \\\n",
    "        --csv_filename=keys_and_background/annotations.csv \\\n",
    "        --output_path=tfrecord_output\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import io\n",
    "import hashlib\n",
    "import PIL\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from absl import flags\n",
    "from absl import logging\n",
    "from absl import app\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "\n",
    "flags.DEFINE_string('img_dir', '', 'Root directory to images dataset.')\n",
    "flags.DEFINE_string('csv_filename', 'train', 'CSV annotations of the images.')\n",
    "flags.DEFINE_string('output_path', '', 'Path to output TFRecord')\n",
    "\n",
    "SAMPLES_PER_FILES = 5000\n",
    "\n",
    "\n",
    "\n",
    "def convert_csv_to_tfrecord(annotation_filename, image_dir, output_path):\n",
    "    data_csv = pd.read_csv(annotation_filename)\n",
    "    splitted_dfs = [data_csv.loc[i:i+SAMPLES_PER_FILES-1,:] for i in range(0, len(data_csv), SAMPLES_PER_FILES)]    \n",
    "    for tf_idx, df in enumerate(splitted_dfs):\n",
    "        tf_filename = get_output_filename(output_path, 'keys', tf_idx)\n",
    "        with tf.io.TFRecordWriter(tf_filename) as tfrecord_writer:\n",
    "            for i in df.index:\n",
    "                add_to_tfrecord(df.loc[i], image_dir, tfrecord_writer)\n",
    "\n",
    "\n",
    "def main(_):\n",
    "    convert_csv_to_tfrecord(FLAGS.csv_filename, FLAGS.img_dir, FLAGS.output_path)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  app.run(main)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
